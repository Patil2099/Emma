{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Emma \u00b6 Emma Memory and Mapfile Analyser (Emma) Conduct static (i.e. worst case) memory consumption analyses based on arbitrary linker map files. It produces extensive .csv files which are easy to filter and post-process. Optionally .html and markdown reports as well as neat figures help you visualising your results. Given a map file input (Green Hills map files are the default but others - like GCC - are supported via configuration options; examples are enclosed) Emma map s the addresses of sections (aka images) and/or objects (aka modules) to memory regions (all addresses given via map files must be known during compile time). Those memory regions are classified into two levels of granularity respectively. The first level defines arbitrary groups based on your personal taste (however using names similar to those defined by your microcontroller vendor makes most sense). Later each of those regions (second level) are assigned to one of four generalised predefined memory regions (those are: INT_RAM , INT_FLASH , EXT_RAM , EXT_FLASH ). In case of virtual memory objects and sections lying within virtual address spaces (VASes) get translated back into physical memory . This is depicted in the figure above (lower part). Categorisation can be used to assign consumers (a consumer would usually represent a software component) to each object or section. This is useful for subsequent steps in order to display memory consumption per consumer type. See the upper part of the figure shown above. Mechanisms are provided to batch categorise object and section names. \"Objects in sections\" provides ways to obtain a finer granularity of the categorisation result . Therefore categorised sections containing (smaller) objects of a different category got split up and result into a more accurate categorisation. As a result you will get output files in form of a .csv file which sets you up to do later processing on this data easily. In this file additional information is added like: Overlaps (of sections/objects) Containments (e.g. sections containing objects) Duplicates All meta data about the origin of each section/object (mapfile, addess space, ...) ... Holding the aforementioned augmented data makes it easy to detect issues in linker scripts and get an in-depth understanding of your program's memory consumption . Including a lot of additional and \"corrected\" data can cause confusion. Thus all original (unmodified) data is preserved in the output files simultaneously. The Emma visualiser helps you to create nice plots and reports in a .png and .html and markdown file format. The whole Emma tool suite contains command line options making it convenient to be run on a build server like --Werror (treat all warnings as errors) or --no-prompt (exit and fail on user prompts; user prompts can happen when ambiguous configurations appear such as multiple matches for one configured map files). Installation \u00b6 1 pip3 install pypiemma Dependencies: Python 3.6 or higher; pip3 install Pygments Markdown matplotlib pandas pypiscout General Workflow \u00b6 The following figure shows a possible workflow using Emma: Emma - as the core component - produces an intermediate .csv file. Inputs are mapfiles and JSON files (for configuration (memory layout, sizes, ...)). From this point you are very flexible to choose your own pipeline. You could use the Emma tools ( Emma Visualiser , Emma Deltas , ...) for further processing (data aggregation and analysis) , simply your favourite spreadsheet software (like Microsoft Excel or LibreOffice Calc) or use your own tool for the data analysis. Quick Start Guide \u00b6 At this point we want to give you a brief overview what to do in the below two scenarios. If you want to play around go to (project files are already present) and use our example projects in ./doc/test_project* . if the Emma project is already set-up (JSON files were created) and you want to analyse your software with newly generated mapfiles proceed to -> Project files are already present or you start your analysis from scratch and need to do configure Emma before you use it then go to -> Project files have to be created . Example projects (including Emma* outputs/results) can be found in ./doc/test_project* . Since version 3.1 Emma can be called in two ways (if you want to run it from the installation folder) where the following variant is recommended: 1 python Emma.py a --project doc/test_project --mapfiles doc/test_project/mapfiles --noprompt The following table provides an overview how you call Emma: Emma module Entry point + \\<options>) (if installed via pip ) Top level sub-command (tlsc) ( python Emma.py \\<tlsc>) Module ( python -m + \\<module> \\<options>) Analyser emma a Emma.emma Visualiser emma_vis v Emma.emma_vis Deltas emma_deltas d Emma.emma_deltas Project files are already present \u00b6 Try python Emma.py a --help to see all possible options or refer to the documentation ( ./doc/* ). Create intermediate .csv from mapfiles with Emma: 1 python Emma.py a -p . \\M yProjectFolder --map . \\M yProjectFolder \\m apfiles --dir . \\M yProjectFolder \\a nalysis --subdir Analysis_1 Generate reports and graphs with Emma Visualiser: 1 python Emma.py v -p . \\M yProjectFolder --dir . \\M yProjectFolder \\a nalysis --subdir Analysis_1 -q Project files that have to be created \u00b6 To create a new project, the following files must be created: globalConfig.json budgets.json categories.json categoriesKeywords.json categoriesSections.json categoriesSectionsKeywords.json You will find example projects in ./doc/test_project* . In-depth documentation can be found in the full documentation (see ./doc/ ). A basic configuration can be short per file. For complex systems you can choose from many optional keywords/options that will provide you means to adjust your analysis as fine grained as you wish. One main concept includes the globalConfig.json . You can see this as meta-config. Each configuration ID (configID) is a separately conducted analysis. Per configID you state individually the configuration files you want to use for this exact analysis. Herewith you can mix and match any combination of subconfigs you prefer. A globalConfig.json could look like this: 1 2 3 4 5 6 7 { \"configID1\" : { \"addressSpacesPath\" : \"addressSpaces.json\" , \"sectionsPath\" : \"sections.json\" , \"patternsPath\" : \"patterns.json\" } } Full documentation \u00b6 For the full documentation please refer to the ./doc/ directory. Contribute \u00b6 We are glad if you want to participate. In ./doc/dev-guide.md you will find a guide telling you everything you need to know including coding conventions and more. Mailing List \u00b6 1 emma-dev (. at) googlegroups.com Dependencies & Licences \u00b6 Library (version) pip package name Licence URL Markdown (v3.0.1+) Markdown BSD-3-Clause https://github.com/Python-Markdown/markdown ; https://python-markdown.github.io/ Pandas (v0.23.4+) pandas BSD-3-Clause https://github.com/pandas-dev/pandas/ ; http://pandas.pydata.org/getpandas.html Pygments (v2.3.1+) Pygments BSD-2-Clause https://bitbucket.org/birkenfeld/pygments-main/src/default/ ; http://pygments.org/download/ Matplotlib (v3.0.0+) matplotlib Matplotlib License (BSD compatible) https://matplotlib.org/users/installing.html ; https://github.com/matplotlib/matplotlib SCout (v1.8+) pypiscout MIT https://github.com/holzkohlengrill/SCout Dependencies needed to generate documentation: Utility scripts in ./doc/ need additional dependencies. As a normal user you can ignore this. Library (version) pip package name Licence URL gprof2dot (v2017.9.19+) gprof2dot LGPL-3.0 https://github.com/jrfonseca/gprof2dot pylint (v2.3.1+) pylint GPL-2.0 https://github.com/PyCQA/pylint Please refer to the gprof2dot project site and install its dependencies (this has to be done even if you install Emma via pip) . Note that those modules are invoked via subprocess calls within the ./genDoc/ scripts. Dependencies used for documentation on GitHub pages (separate, independent branch gh-pages ): Utility scripts used to build GitHub pages documentation. As a normal user you can ignore this. Library (version) pip package name Licence URL MkDocs (v1.0.4+) mkdocs BSD-3Clause https://github.com/mkdocs/mkdocs Material for MkDocs (v4.4.1+) mkdocs-material MIT https://github.com/squidfunk/mkdocs-material Code snippets etc.: Name (version) Kind Modified? Licence URL pygmentize (v2.2.0+) Auto-generated .css file Yes BSD-2-Clause http://pygments.org/download/ ; https://bitbucket.org/birkenfeld/pygments-main/issues/1496/question-licence-of-auto-generated-css toHumanReadable (--) Code snippet No MIT https://github.com/TeamFlowerPower/kb/wiki/humanReadable For the full documentation please refer to the ./doc/ directory.","title":"Home"},{"location":"index.html#emma","text":"Emma Memory and Mapfile Analyser (Emma) Conduct static (i.e. worst case) memory consumption analyses based on arbitrary linker map files. It produces extensive .csv files which are easy to filter and post-process. Optionally .html and markdown reports as well as neat figures help you visualising your results. Given a map file input (Green Hills map files are the default but others - like GCC - are supported via configuration options; examples are enclosed) Emma map s the addresses of sections (aka images) and/or objects (aka modules) to memory regions (all addresses given via map files must be known during compile time). Those memory regions are classified into two levels of granularity respectively. The first level defines arbitrary groups based on your personal taste (however using names similar to those defined by your microcontroller vendor makes most sense). Later each of those regions (second level) are assigned to one of four generalised predefined memory regions (those are: INT_RAM , INT_FLASH , EXT_RAM , EXT_FLASH ). In case of virtual memory objects and sections lying within virtual address spaces (VASes) get translated back into physical memory . This is depicted in the figure above (lower part). Categorisation can be used to assign consumers (a consumer would usually represent a software component) to each object or section. This is useful for subsequent steps in order to display memory consumption per consumer type. See the upper part of the figure shown above. Mechanisms are provided to batch categorise object and section names. \"Objects in sections\" provides ways to obtain a finer granularity of the categorisation result . Therefore categorised sections containing (smaller) objects of a different category got split up and result into a more accurate categorisation. As a result you will get output files in form of a .csv file which sets you up to do later processing on this data easily. In this file additional information is added like: Overlaps (of sections/objects) Containments (e.g. sections containing objects) Duplicates All meta data about the origin of each section/object (mapfile, addess space, ...) ... Holding the aforementioned augmented data makes it easy to detect issues in linker scripts and get an in-depth understanding of your program's memory consumption . Including a lot of additional and \"corrected\" data can cause confusion. Thus all original (unmodified) data is preserved in the output files simultaneously. The Emma visualiser helps you to create nice plots and reports in a .png and .html and markdown file format. The whole Emma tool suite contains command line options making it convenient to be run on a build server like --Werror (treat all warnings as errors) or --no-prompt (exit and fail on user prompts; user prompts can happen when ambiguous configurations appear such as multiple matches for one configured map files).","title":"Emma"},{"location":"index.html#installation","text":"1 pip3 install pypiemma Dependencies: Python 3.6 or higher; pip3 install Pygments Markdown matplotlib pandas pypiscout","title":"Installation"},{"location":"index.html#general-workflow","text":"The following figure shows a possible workflow using Emma: Emma - as the core component - produces an intermediate .csv file. Inputs are mapfiles and JSON files (for configuration (memory layout, sizes, ...)). From this point you are very flexible to choose your own pipeline. You could use the Emma tools ( Emma Visualiser , Emma Deltas , ...) for further processing (data aggregation and analysis) , simply your favourite spreadsheet software (like Microsoft Excel or LibreOffice Calc) or use your own tool for the data analysis.","title":"General Workflow"},{"location":"index.html#quick-start-guide","text":"At this point we want to give you a brief overview what to do in the below two scenarios. If you want to play around go to (project files are already present) and use our example projects in ./doc/test_project* . if the Emma project is already set-up (JSON files were created) and you want to analyse your software with newly generated mapfiles proceed to -> Project files are already present or you start your analysis from scratch and need to do configure Emma before you use it then go to -> Project files have to be created . Example projects (including Emma* outputs/results) can be found in ./doc/test_project* . Since version 3.1 Emma can be called in two ways (if you want to run it from the installation folder) where the following variant is recommended: 1 python Emma.py a --project doc/test_project --mapfiles doc/test_project/mapfiles --noprompt The following table provides an overview how you call Emma: Emma module Entry point + \\<options>) (if installed via pip ) Top level sub-command (tlsc) ( python Emma.py \\<tlsc>) Module ( python -m + \\<module> \\<options>) Analyser emma a Emma.emma Visualiser emma_vis v Emma.emma_vis Deltas emma_deltas d Emma.emma_deltas","title":"Quick Start Guide"},{"location":"index.html#project-files-are-already-present","text":"Try python Emma.py a --help to see all possible options or refer to the documentation ( ./doc/* ). Create intermediate .csv from mapfiles with Emma: 1 python Emma.py a -p . \\M yProjectFolder --map . \\M yProjectFolder \\m apfiles --dir . \\M yProjectFolder \\a nalysis --subdir Analysis_1 Generate reports and graphs with Emma Visualiser: 1 python Emma.py v -p . \\M yProjectFolder --dir . \\M yProjectFolder \\a nalysis --subdir Analysis_1 -q","title":"Project files are already present"},{"location":"index.html#project-files-that-have-to-be-created","text":"To create a new project, the following files must be created: globalConfig.json budgets.json categories.json categoriesKeywords.json categoriesSections.json categoriesSectionsKeywords.json You will find example projects in ./doc/test_project* . In-depth documentation can be found in the full documentation (see ./doc/ ). A basic configuration can be short per file. For complex systems you can choose from many optional keywords/options that will provide you means to adjust your analysis as fine grained as you wish. One main concept includes the globalConfig.json . You can see this as meta-config. Each configuration ID (configID) is a separately conducted analysis. Per configID you state individually the configuration files you want to use for this exact analysis. Herewith you can mix and match any combination of subconfigs you prefer. A globalConfig.json could look like this: 1 2 3 4 5 6 7 { \"configID1\" : { \"addressSpacesPath\" : \"addressSpaces.json\" , \"sectionsPath\" : \"sections.json\" , \"patternsPath\" : \"patterns.json\" } }","title":"Project files that have to be created"},{"location":"index.html#full-documentation","text":"For the full documentation please refer to the ./doc/ directory.","title":"Full documentation"},{"location":"index.html#contribute","text":"We are glad if you want to participate. In ./doc/dev-guide.md you will find a guide telling you everything you need to know including coding conventions and more.","title":"Contribute"},{"location":"index.html#mailing-list","text":"1 emma-dev (. at) googlegroups.com","title":"Mailing List"},{"location":"index.html#dependencies-licences","text":"Library (version) pip package name Licence URL Markdown (v3.0.1+) Markdown BSD-3-Clause https://github.com/Python-Markdown/markdown ; https://python-markdown.github.io/ Pandas (v0.23.4+) pandas BSD-3-Clause https://github.com/pandas-dev/pandas/ ; http://pandas.pydata.org/getpandas.html Pygments (v2.3.1+) Pygments BSD-2-Clause https://bitbucket.org/birkenfeld/pygments-main/src/default/ ; http://pygments.org/download/ Matplotlib (v3.0.0+) matplotlib Matplotlib License (BSD compatible) https://matplotlib.org/users/installing.html ; https://github.com/matplotlib/matplotlib SCout (v1.8+) pypiscout MIT https://github.com/holzkohlengrill/SCout Dependencies needed to generate documentation: Utility scripts in ./doc/ need additional dependencies. As a normal user you can ignore this. Library (version) pip package name Licence URL gprof2dot (v2017.9.19+) gprof2dot LGPL-3.0 https://github.com/jrfonseca/gprof2dot pylint (v2.3.1+) pylint GPL-2.0 https://github.com/PyCQA/pylint Please refer to the gprof2dot project site and install its dependencies (this has to be done even if you install Emma via pip) . Note that those modules are invoked via subprocess calls within the ./genDoc/ scripts. Dependencies used for documentation on GitHub pages (separate, independent branch gh-pages ): Utility scripts used to build GitHub pages documentation. As a normal user you can ignore this. Library (version) pip package name Licence URL MkDocs (v1.0.4+) mkdocs BSD-3Clause https://github.com/mkdocs/mkdocs Material for MkDocs (v4.4.1+) mkdocs-material MIT https://github.com/squidfunk/mkdocs-material Code snippets etc.: Name (version) Kind Modified? Licence URL pygmentize (v2.2.0+) Auto-generated .css file Yes BSD-2-Clause http://pygments.org/download/ ; https://bitbucket.org/birkenfeld/pygments-main/issues/1496/question-licence-of-auto-generated-css toHumanReadable (--) Code snippet No MIT https://github.com/TeamFlowerPower/kb/wiki/humanReadable For the full documentation please refer to the ./doc/ directory.","title":"Dependencies &amp; Licences"},{"location":"dev-guide.html","text":"Developer Guide \u00b6 Contribution guide \u00b6 This guide will assist you in order to successfully submit contributions for the Emma project. Obtain the current version of the source code \u00b6 Assure that you are working with the latest stable version. Describe your changes \u00b6 Absolutely describe your changes regardless of what problem you solved nor how complex your changes are. Keep the following points in mind: General \u00b6 What is your motivation to do to this change? Why it is worth fixing? How will it affect end-user? If optimisations were done - quantify them. Present trade-offs (e.g. run-time vs. memory). Evaluate your contribution objectively. What are pro's, con's? One contribution should solve only one problem. If not split it. Your description should be self-explanatory (avoiding external resources). Linking, referencing & documentation \u00b6 If you link to tickets/mailing lists etc. reference to them. Summarise what is its principal outcome. When referencing specific commits: state the commit ID (use the long hash) + (!) the commit massage in order to make it more readable for the reviewer. Implementation specific \u00b6 How you solved the problem? If your solution is complex: provide an introduction before going into details. If your patch your solution describe what you have done and why. Test and review your code \u00b6 Test it on a clean environment. Review your code with regards to our coding guidelines . Check and act on the review process \u00b6 You may receive comments regarding your submission. In order to be considered you must respond to those comments. Sign your work \u00b6 You must sign the Developer Certificate of Origin (DCO) for any submission. We use this to keep track of who contributed what. Additionaly you certify that the contribution is your own work or you have the right to pass it on as an open-source patch. To do so you read the DCO and agree by adding a \"sign-off\" line at the end of the explanation of the patch like in the example below: 1 Signed-off-by: Joe Contrib <joe.contrib@somedomain.com> Fill in your full name (no pseudonyms) and your email address surrounded by angle brackets. Small or formal changes can be done in square bracket notation: 1 2 3 Signed - off - by : Joe Contrib < joe . contrib @somedomain . com > [ alice.maintain@somedomain.com: struct foo moved from foo.c to foo.h ] Signed - off - by : Alice Maintain < alice . maintain @somedomain . com > Do the pull request \u00b6 1 git request - pull master git : // repo - url . git my - signed - tag See also here for more information about pull requests in general on GitHub. Coding guidelines \u00b6 Generally PEP-8 or the Google style guide apply. However we deviate slightly from this (see the following sections). If in doubt run pylint by using our pylint configuration file ( .pylintrc ). Style \u00b6 Naming conventions mixedCase (camelCase and PascalCase is used) Methods/functions and variables start with a minuscule ( camelCase ) Class names names start with a majuscule ( PascalCase ) Global variables: CAPS_WITH_UNDER Max line length rule is ignored since it decreases readability, use line-breaks where appropriate Imports in Python The imports need to be separated from other parts of the file with 2-2 blank lines above and under They need to be grouped into the following three groups: Python Standard Library Imports 3rd Party Imports Emma Imports The groups need to be in the same order as in the previous list and they need to be separated from each other with a single blank line Only packages and modules shall be imported, individual classes and functions not Imports shall not use renaming There are some exceptions: Importing from shared_libs.stringConstants shall be done in the following way: from shared_libs.stringConstants import * Importing the pyipiscout library shall be done in the following way: import pypiscout as sc British English shall be used in function names and comments Exceptions: map file is always written as mapfile TODO , FIXME and similar tags should be in the format: # TODO: This is my TODO (<author>) First letter in the comment is a majuscule The comment ends with the name of the author or with an unique and consistent abbreviation/alias/username/pseudonym (preferably your initials if still available; if you are unsure check the CONTRIBUTORS file) Path handling \u00b6 Use os.path.normpath() where appropriate. Using / and \\ can cause problems between OSes (even on Windows with WSL) and strange things could happen. Also prefer joinPath() (in shared_libs.Emma_helper ) instetad of os.path.join() . Raising exceptions \u00b6 Exceptions should be avoided where possible. Instead use a descriptive error message using SCout and exit with sys.exit(<err-code>) the default error code is -10 For the user it is hard to distinquish whether an exception was caused by a bug or wrong user input Adding compiler support \u00b6 The Emma tool was created in order to collect information from mapfiles and write them to CSV documents. These mapfiles are created by the compiler during the compilation of a software and their format is specific to the compiler used. Emma was designed in a way, that adding support for new compilers is possible with only minor changes to the existing codebase. This chapter explains what are the new components that need to be added and how to integrate them into Emma. Compiler handling \u00b6 The globalConfig.json file of a configuration lists the configId-s of the project (see doc/readme-emma.md for more info on Emma configurations). Every configId has a key \"compiler\" (for example see the doc/test_project configuration). The value belonging to this key determines the classes used during runtime for the compiler specific tasks. New classes that need to be added \u00b6 To implement the support for a new compiler, new classes need to be developed. These will be responsible for reading the compiler specific parts of the configuration and for processing the mapfiles. These classes should be located in the emma_libs folder, and it is recommended that they contain the name of the compiler they belong to as a prefix, for example: emma_libs/ghsConfiguration.py These new classes need to provide a specific interface. For this reason the following classes need to be subclassed: From emma_libs/specificConfiguration.py : SpecificConfiguration From emma_libs/mapfileProcessor.py : MapfileProcessor Changes need to be done on the existing codebase \u00b6 In order to integrate these new classes, the following changes need to be made: Adding name string constant for the new compiler The file shared_libs/stringConstants.py contains the names of the supported compiler For consistency the name strings should follow the format defined in the CMake documentation Example: COMPILER_NAME_GHS = \"GHS\" Extending the SpecificConfiguration factory The file emma_libs/specificConfigurationFactory.py contains the function createSpecificConfiguration(compiler, **kwargs) This function is responsible for creating objects of subclasses of the SpecificConfiguration class that are specific to a compiler Here, using the previously defined compiler name constant a new entry has to be made Extending the MapfileProcessor factory The file emma_libs/mapfileProcessorFactory.py contains the function createSpecificMapfileProcesor(compiler, **kwargs) This function is responsible for creating objects of subclasses of the MapFileProcessor class that are specific to a compiler Here, using the previously defined compiler name constant a new entry has to be made Expected functionality of the new components \u00b6 The previously mentioned abstract classes from which the new classes need to inherit, describe the prototypes of the methods that need to be implemented in their docstrings. During runtime these methods (the ones with green background) will be called in the following order: The methods need to implement the following functionality: readConfiguration() Process all the config files under the configurationPath that are belonging to the configId , the function was called with Extend the configuration dictionary that was given to the function with the data extracted (this already contains the compiler independent configuration) Collect the mapfiles from the mapfilesPath based on the configuration checkConfiguration() Check whether the configuration belonging to the configId is valid, meaning that the mapfile processing will be possible with it Return True for a valid configuration , False otherwise (in the False case, Emma might skip the mapfile processing for this configId ) processMapfiles() Create and return two lists of MemEntry objects that are representing the sections and objects found in the mapfiles respectively The lists need to be ordered in an ascending order based on the addressStart of the MemEntry objects The following members need to be filled out in the MemEntry objects: configId mapfileName addressStart addressLength or addressEnd sectionName objectName compilerSpecificData Before returning, call the MapfileProcessor::fillOutMemoryRegionsAndMemoryTypes() on the created lists to fill out the memTypeTag and memType members Expected changes to project and documentation after adding a new compiler support \u00b6 To make it possible for users and other contributors to easily get started with the added new support, the following non code related changes need to made: Add a test project with a step-by-step introduction to the doc folder. Take the doc/test_project as example. Add a chapter to the doc/readme-emma.md describing the configuration of the new compiler. Take the chapter Formal Definition of the GHS compiler specific configuration as example. After changing the Markdown files, please re-generate the HTML files with the genDoc/genReadmeHtmlFromMd.py script, using the --no_graphs command line argument. Colour palette \u00b6 The following colour palette is used for the documentation: Colour HSL(A) RGB(A) RGBA (hex) Yellow 34, 255, 192 255, 230, 128 ffe680ff Light orange 17, 255, 213 255, 204, 170 ffccaaff Dark orange 17, 145, 204 233, 198, 175 e9c6afff Light blue 136, 145, 204 175, 221, 233 afdde9ff Green 68, 145, 204 198, 233, 175 c6e9afff Light grey 0, 0, 236 236, 236, 236 ecececff Grey 0, 0, 204 204, 204, 204 ccccccff","title":"Developer Guide"},{"location":"dev-guide.html#developer-guide","text":"","title":"Developer Guide"},{"location":"dev-guide.html#contribution-guide","text":"This guide will assist you in order to successfully submit contributions for the Emma project.","title":"Contribution guide"},{"location":"dev-guide.html#obtain-the-current-version-of-the-source-code","text":"Assure that you are working with the latest stable version.","title":"Obtain the current version of the source code"},{"location":"dev-guide.html#describe-your-changes","text":"Absolutely describe your changes regardless of what problem you solved nor how complex your changes are. Keep the following points in mind:","title":"Describe your changes"},{"location":"dev-guide.html#general","text":"What is your motivation to do to this change? Why it is worth fixing? How will it affect end-user? If optimisations were done - quantify them. Present trade-offs (e.g. run-time vs. memory). Evaluate your contribution objectively. What are pro's, con's? One contribution should solve only one problem. If not split it. Your description should be self-explanatory (avoiding external resources).","title":"General"},{"location":"dev-guide.html#linking-referencing-documentation","text":"If you link to tickets/mailing lists etc. reference to them. Summarise what is its principal outcome. When referencing specific commits: state the commit ID (use the long hash) + (!) the commit massage in order to make it more readable for the reviewer.","title":"Linking, referencing &amp; documentation"},{"location":"dev-guide.html#implementation-specific","text":"How you solved the problem? If your solution is complex: provide an introduction before going into details. If your patch your solution describe what you have done and why.","title":"Implementation specific"},{"location":"dev-guide.html#test-and-review-your-code","text":"Test it on a clean environment. Review your code with regards to our coding guidelines .","title":"Test and review your code"},{"location":"dev-guide.html#check-and-act-on-the-review-process","text":"You may receive comments regarding your submission. In order to be considered you must respond to those comments.","title":"Check and act on the review process"},{"location":"dev-guide.html#sign-your-work","text":"You must sign the Developer Certificate of Origin (DCO) for any submission. We use this to keep track of who contributed what. Additionaly you certify that the contribution is your own work or you have the right to pass it on as an open-source patch. To do so you read the DCO and agree by adding a \"sign-off\" line at the end of the explanation of the patch like in the example below: 1 Signed-off-by: Joe Contrib <joe.contrib@somedomain.com> Fill in your full name (no pseudonyms) and your email address surrounded by angle brackets. Small or formal changes can be done in square bracket notation: 1 2 3 Signed - off - by : Joe Contrib < joe . contrib @somedomain . com > [ alice.maintain@somedomain.com: struct foo moved from foo.c to foo.h ] Signed - off - by : Alice Maintain < alice . maintain @somedomain . com >","title":"Sign your work"},{"location":"dev-guide.html#do-the-pull-request","text":"1 git request - pull master git : // repo - url . git my - signed - tag See also here for more information about pull requests in general on GitHub.","title":"Do the pull request"},{"location":"dev-guide.html#coding-guidelines","text":"Generally PEP-8 or the Google style guide apply. However we deviate slightly from this (see the following sections). If in doubt run pylint by using our pylint configuration file ( .pylintrc ).","title":"Coding guidelines"},{"location":"dev-guide.html#style","text":"Naming conventions mixedCase (camelCase and PascalCase is used) Methods/functions and variables start with a minuscule ( camelCase ) Class names names start with a majuscule ( PascalCase ) Global variables: CAPS_WITH_UNDER Max line length rule is ignored since it decreases readability, use line-breaks where appropriate Imports in Python The imports need to be separated from other parts of the file with 2-2 blank lines above and under They need to be grouped into the following three groups: Python Standard Library Imports 3rd Party Imports Emma Imports The groups need to be in the same order as in the previous list and they need to be separated from each other with a single blank line Only packages and modules shall be imported, individual classes and functions not Imports shall not use renaming There are some exceptions: Importing from shared_libs.stringConstants shall be done in the following way: from shared_libs.stringConstants import * Importing the pyipiscout library shall be done in the following way: import pypiscout as sc British English shall be used in function names and comments Exceptions: map file is always written as mapfile TODO , FIXME and similar tags should be in the format: # TODO: This is my TODO (<author>) First letter in the comment is a majuscule The comment ends with the name of the author or with an unique and consistent abbreviation/alias/username/pseudonym (preferably your initials if still available; if you are unsure check the CONTRIBUTORS file)","title":"Style"},{"location":"dev-guide.html#path-handling","text":"Use os.path.normpath() where appropriate. Using / and \\ can cause problems between OSes (even on Windows with WSL) and strange things could happen. Also prefer joinPath() (in shared_libs.Emma_helper ) instetad of os.path.join() .","title":"Path handling"},{"location":"dev-guide.html#raising-exceptions","text":"Exceptions should be avoided where possible. Instead use a descriptive error message using SCout and exit with sys.exit(<err-code>) the default error code is -10 For the user it is hard to distinquish whether an exception was caused by a bug or wrong user input","title":"Raising exceptions"},{"location":"dev-guide.html#adding-compiler-support","text":"The Emma tool was created in order to collect information from mapfiles and write them to CSV documents. These mapfiles are created by the compiler during the compilation of a software and their format is specific to the compiler used. Emma was designed in a way, that adding support for new compilers is possible with only minor changes to the existing codebase. This chapter explains what are the new components that need to be added and how to integrate them into Emma.","title":"Adding compiler support"},{"location":"dev-guide.html#compiler-handling","text":"The globalConfig.json file of a configuration lists the configId-s of the project (see doc/readme-emma.md for more info on Emma configurations). Every configId has a key \"compiler\" (for example see the doc/test_project configuration). The value belonging to this key determines the classes used during runtime for the compiler specific tasks.","title":"Compiler handling"},{"location":"dev-guide.html#new-classes-that-need-to-be-added","text":"To implement the support for a new compiler, new classes need to be developed. These will be responsible for reading the compiler specific parts of the configuration and for processing the mapfiles. These classes should be located in the emma_libs folder, and it is recommended that they contain the name of the compiler they belong to as a prefix, for example: emma_libs/ghsConfiguration.py These new classes need to provide a specific interface. For this reason the following classes need to be subclassed: From emma_libs/specificConfiguration.py : SpecificConfiguration From emma_libs/mapfileProcessor.py : MapfileProcessor","title":"New classes that need to be added"},{"location":"dev-guide.html#changes-need-to-be-done-on-the-existing-codebase","text":"In order to integrate these new classes, the following changes need to be made: Adding name string constant for the new compiler The file shared_libs/stringConstants.py contains the names of the supported compiler For consistency the name strings should follow the format defined in the CMake documentation Example: COMPILER_NAME_GHS = \"GHS\" Extending the SpecificConfiguration factory The file emma_libs/specificConfigurationFactory.py contains the function createSpecificConfiguration(compiler, **kwargs) This function is responsible for creating objects of subclasses of the SpecificConfiguration class that are specific to a compiler Here, using the previously defined compiler name constant a new entry has to be made Extending the MapfileProcessor factory The file emma_libs/mapfileProcessorFactory.py contains the function createSpecificMapfileProcesor(compiler, **kwargs) This function is responsible for creating objects of subclasses of the MapFileProcessor class that are specific to a compiler Here, using the previously defined compiler name constant a new entry has to be made","title":"Changes need to be done on the existing codebase"},{"location":"dev-guide.html#expected-functionality-of-the-new-components","text":"The previously mentioned abstract classes from which the new classes need to inherit, describe the prototypes of the methods that need to be implemented in their docstrings. During runtime these methods (the ones with green background) will be called in the following order: The methods need to implement the following functionality: readConfiguration() Process all the config files under the configurationPath that are belonging to the configId , the function was called with Extend the configuration dictionary that was given to the function with the data extracted (this already contains the compiler independent configuration) Collect the mapfiles from the mapfilesPath based on the configuration checkConfiguration() Check whether the configuration belonging to the configId is valid, meaning that the mapfile processing will be possible with it Return True for a valid configuration , False otherwise (in the False case, Emma might skip the mapfile processing for this configId ) processMapfiles() Create and return two lists of MemEntry objects that are representing the sections and objects found in the mapfiles respectively The lists need to be ordered in an ascending order based on the addressStart of the MemEntry objects The following members need to be filled out in the MemEntry objects: configId mapfileName addressStart addressLength or addressEnd sectionName objectName compilerSpecificData Before returning, call the MapfileProcessor::fillOutMemoryRegionsAndMemoryTypes() on the created lists to fill out the memTypeTag and memType members","title":"Expected functionality of the new components"},{"location":"dev-guide.html#expected-changes-to-project-and-documentation-after-adding-a-new-compiler-support","text":"To make it possible for users and other contributors to easily get started with the added new support, the following non code related changes need to made: Add a test project with a step-by-step introduction to the doc folder. Take the doc/test_project as example. Add a chapter to the doc/readme-emma.md describing the configuration of the new compiler. Take the chapter Formal Definition of the GHS compiler specific configuration as example. After changing the Markdown files, please re-generate the HTML files with the genDoc/genReadmeHtmlFromMd.py script, using the --no_graphs command line argument.","title":"Expected changes to project and documentation after adding a new compiler support"},{"location":"dev-guide.html#colour-palette","text":"The following colour palette is used for the documentation: Colour HSL(A) RGB(A) RGBA (hex) Yellow 34, 255, 192 255, 230, 128 ffe680ff Light orange 17, 255, 213 255, 204, 170 ffccaaff Dark orange 17, 145, 204 233, 198, 175 e9c6afff Light blue 136, 145, 204 175, 221, 233 afdde9ff Green 68, 145, 204 198, 233, 175 c6e9afff Light grey 0, 0, 236 236, 236, 236 ecececff Grey 0, 0, 204 204, 204, 204 ccccccff","title":"Colour palette"},{"location":"readme-emma.html","text":"Emma \u00b6 Emma Memory and Mapfile Analyser Conduct static (i.e. worst case) memory consumption analyses based on linker map files (currently only Green Hills map files are supported). This tool creates a summary/overview about static memory usage in form of a comma separated values (CSV) file. Requirements \u00b6 Python 3.6 or higher Python libraries pypiscout 2.0 or higher: ( pip3 install pypiscout ) Tested on Windows and Linux systems Process \u00b6 Using the Mapfile Analyser is a two step process. The first step is to extract the required information from the mapfiles and save it to .csv files. This is done with the Emma.py a script. The second step is to visualise the data. This document explains the first part only, the visualisation is documented in the Emma visualiser readme document. Limitations \u00b6 The Emma is only suitable for analyzing projects where the devices have a single linear physical address space: Devices that use for example the Intel 8051 architecture have separate code and data address spaces that both start at address 0x0000. Devices based on architectures like this can not be analyzed with Emma. Devices that use for example the ARMv6M architecture have a single linear address space. Devices based on architectures like this can be analyzed with Emma. Arguments \u00b6 Required Arguments \u00b6 1 2 3 --project PROJECT, -p PROJECT --mapfiles MAPFILES, --map MAPFILES Optional Arguments \u00b6 --dir User defined path for the top folder holding the memStats /output files. Per default it uses the same directory as the config files. --stats_dir User defined path inside the folder given in the --dir argument. This is usefull when batch analysing mapfiles from various development stages. Every analysis output gets it's own directory. --create_categories Create categories*.json from categories*Keywords.json for easier categorisation. --remove_unmatched , Remove unmatched entries from categories*.json . This is useful when a categories*.json from another project is used. --analyse_debug , --dbg Normally we remove DWARF debug sections from the analysis to show the relevant information for a possible release software. This can be prevented if this argument is set. DWARF section names are defined in stringConstants.py . .unused_ram is always excluded (regardless of this flag) --noprompt Exit and fail on user prompt. Normally this happens when some files or configurations are ambiguous. This is useful when running Emma on CI systems. Project Configuration \u00b6 The memory analysis will be executed based on the project configuration. In order to be able to use Emma with your project, you need to create a configuration matching your project's hardware and software. Configure Emma with high diligence since errors may lead to incorrect results of your analysis . During the analysis Emma performs some sanity checks which helps you detecting misconfiguration. This chapter explains the role and functionality of each part of the configuration and illustrates all the settings that can be used. Based on this description the user will have to create his/her own configuration. Creating a configuration is done by writing several JSON files (if you are not familiar with JSON, please visit https://www.json.org ). This chapter will go trough the topic by formally defining the format, rules and the functionality of the config files. There are practical example projects available in the doc folder. These projects will lead you step by step trough the process of creating a configuration and they also contain map files that can be analyzed. Currently the following example projects are available: doc/test_project - A project that illustrates a system with a hardware that consists of two devices: an MCU and an SOC. Both of the devices have a GHS compiler specific configuration and mapfiles. An Emma project configuration consists of two parts: the generic configuration and the compiler specific configuration. Formal definition of the generic configuration \u00b6 The generic part of the configuration contains the following files: 1 2 3 4 5 6 7 8 9 10 + -- [<PROJECT>] | + -- [supplement] | + -- globalConfig.json | + -- addressSpaces*.json | + -- budgets.json | + -- categoriesObjects.json | + -- categoriesObjectsKeywords.json | + -- categoriesSections.json | + -- categoriesSectionsKeywords.json | + -- <COMPILER_SPECIFIC_CONFIGURATION_FILES> The files containing the asterisk symbol can be freely named by the user because the actual file names will have to be listed in the globalConfig.json. PROJECT \u00b6 The configuration has to be contained by a folder. The name of the folder will be the name of the configuration. From the files ending with a * symbol, the configuration can contain more than one but maximum up to the number of configIDs defined in globalConfig.json. supplement \u00b6 You can add .md files into this folder with Markdown syntax to add information regarding your project that will be contained by the .html overview. For more information please refer to the Emma Visualiser's documentation. globalConfig.json \u00b6 The globalConfig.json is the starting point of a configuration, this file defines the configId -s. The configId-s are the hardware units of the system that have memory associated to them, for example an MCU, MPU or an SOC. During the analysis, it will be examined to which extent these memory resources are used. For each configId, globalConfig.json assigns a compiler. This means that the mapfiles belonging to the configId were created by the selected compiler. This is important, since the format of these files are specific to the compiler. For each configId an addressSpaces*.json config file will be assigned. Furthermore the globalConfig.json assigns compiler specific config files to each configId, that need to be consistent with the selected compiler. For example if a GHS compiler was selected to the configId, then the compiler specific configuration part of this configId have to fulfill the requirements described in the Formal Definition of the GHS compiler specific configuration chapter. The globalConfig.json has to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"<CONFIG_ID>\" : { \"compiler\" : \"<COMPILER_NAME>\" , \"addressSpacesPath\" : \"<CONFIG_FILE>\" , \"mapfiles\" : \"<MAPFILES_REL_PATH>\" , \"ignoreConfigID\" : \"<BOOL>\" , <COMPILER_SPECIFIC_KEY_VALUE_PAIRS> }, . . . \"<CONFIG_ID>\" : { \"compiler\" : \"<COMPILER_NAME>\" , \"addressSpacesPath\" : \"<CONFIG_FILE>\" , \"mapfiles\" : \"<MAPFILES_REL_PATH>\" , \"ignoreConfigID\" : \"<BOOL>\" , <COMPILER_SPECIFIC_KEY_VALUE_PAIRS> } } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <CONFIG_ID> is a string <COMPILER_NAME> is a string <CONFIG_FILE> is a string <MAPFILES_REL_PATH> is a string, with the special characters escaped in it <BOOL> is a boolean value containing either true or false <COMPILER_SPECIFIC_KEY_VALUE_PAIRS> are the key-value pairs that are required by the selected compiler There has to be at least one configID defined You must select a compiler for every configID, by defining the compiler key. The possible values are: \"GHS\" - Green Hills Compiler You must assign the following config files for each configID by defining the following key, value pairs: by defining addressSpacesPath , the config file that defines the address spaces is assigned The config files have to be in the same folder as the globalConfig.json The config files don't need to be different for each configID (for example you can use the same address spaces config file for all the configIDs) The mapfiles: specifies a folder relative to the one given via --mapfiles command line argument is optional, if is defined for a configID, then the map files belonging to this configId will be searched for within this folder Otherwise the mapfiles will be searched for in the --mapfiles root map file path The ignoreConfigID: can be used to mark a configID as ignored, which means that this will not be processed during the analysis is optional, it does not need to be included in every configID, leaving it has the same effect as including it with false addressSpaces*.json \u00b6 The address spaces config files define the existing memory areas for the configIDs they were assigned to in the globalConfigs.json. These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"offset\" : \"<ADDRESS>\" , \"memory\" : { \"<MEMORY_AREA>\" : { \"start\" : \"<ADDRESS>\" , \"end\" : \"<ADDRESS>\" , \"type\" : \"<MEMORY_TYPE>\" }, . . . \"<MEMORY_AREA>\" : { \"start\" : \"<ADDRESS>\" , \"end\" : \"<ADDRESS>\" , \"type\" : \"<MEMORY_TYPE>\" } }, \"ignoreMemory\" : [ \"<MEMORY_AREA>\" , ... \"<MEMORY_AREA>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <ADDRESS> is a string containing a 64bit hexadecimal value, for example \"0x1FFFFFFF\" <MEMORY_AREA> is a string containing a unique name <MEMORY_TYPE> is a string containing one of the following values: \"INT_RAM\" - internal RAM \"EXT_RAM\" - external RAM \"INT_FLASH\" - internal Flash \"EXT_FLASH\" - external Flash The offset is a global address offset applied to all addresses in the file memory is a JSON object that defines the memory areas Each memory area is a JSON object that has three elements: start - start address end - end address type - memory type The ignoreMemory is a JSON array used to mark one or more <MEMORY_AREA> to be ignored during the analysis: The the elements of this array can be selected from the ones defined in the \"memory\" object It is optional, not including it or including it as an empty array means none of the <MEMORY_AREA> s are ignored budgets.json \u00b6 The budgets config file belongs to the Emma Visualiser. For a description, please see: doc/readme-vis.md . categoriesObjects.json and categoriesSections.json \u00b6 The categories config files are used to categorize objects and sections to user defined categories by using their full names. These files are optional, if no categorization needed, these config files do not need to be created. This function can be used for example to group the software components of one company together which will make the results easier to understand. The categoriesObjects.json is used for the objects and the categoriesSections.json is used for the section categorization. The objects and sections will be first tried to be categorized by these files. If they could not be categorized, then the software will try to categorize them based on the categoriesObjectsKeywords.json and categoriesSectionsKeywords.json files. These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"<CATEGORY>\" : [ \"<NAME>\" , . . . \"<NAME>\" ], . . . \"<CATEGORY>\" : [ \"<NAME>\" , . . . \"<NAME>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <CATEGORY> is a string containing a unique category name <NAME> is a string The categorisation can be done either by hand or with the --create_categories command line argument (for usage see there) The <NAME> has to contain full names of the sections or objects categoriesObjectsKeywords.json and categoriesSectionsKeywords.json \u00b6 The categories keywords config files are used to categorize objects and sections to user defined categories by using only substrings of their names. These files are optional, if no categorization needed, these config files do not need to be created. This function can be used for example to group the software components of one company together which will make the results easier to understand. The categoriesObjectsKeywords.json is used for the objects and the categoriesSectionsKeywords.json is used for the section categorization. The objects and sections will only tried to be categorized by these files if the categorization by the categoriesObjects.json and categoriesSections.json files failed. If they could not be categorized, then the software will assign them to a category called <Emma_UnknownCategory> so they will be more visible in the results. These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"<CATEGORY>\" : [ \"<KEYWORD>\" , . . . \"<KEYWORD>\" ], \"<CATEGORY>\" : [ \"<KEYWORD>\" , . . . \"<KEYWORD>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <CATEGORY> is a string containing a unique category name <KEYWORD> is a string The categorisation has to be done by hand The <KEYWORD> contains a regex pattern for the names of the sections or objects Formal Definition of the GHS compiler specific configuration \u00b6 The GHS compiler specific part of the configuration contains the following files: 1 2 3 4 + -- [<PROJECT>] | + -- <GENERIC_CONFIGURATION_FILES> | + -- patterns*.json | + -- virtualSections*.json The following dependencies exist within this type of a configuration: In globalConfig.json , you need to reference (ref relations on the picture): addressSpaces*.json patterns*.json sections*.json memRegionExcludes : You can exclude certain memory regions with this keyword in patterns*.json . In order to do this the memory regions/tags must match with those defined in addressSpaces*.json . If you have virtual address spaces (VASes) defined. You need a \"monolith file\" pattern defined in patterns*.json in order to be able to translate virtual addresses back to physical addresses. In the same file you give each VAS a name. This name is later used to identify which section belongs to which VAS (defined in virtualSections*.json ). The VAS names must match between those two files. This is needed in order to avoid name clashes of sections names between different VASes. Extensions to the globalConfig.json \u00b6 The globalConfig.json has to have the following format for configId-s that have selected \"GHS\" as compiler : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"<CONFIG_ID>\" : { <GENERIC_KEY_VALUE_PAIRS>, \"patternsPath\" : \"<CONFIG_FILE>\" , \"virtualSectionsPath\" : \"<CONFIG_FILE>\" }, . . . \"<CONFIG_ID>\" : { <GENERIC_KEY_VALUE_PAIRS>, \"patternsPath\" : \"<CONFIG_FILE>\" , \"virtualSectionsPath\" : \"<CONFIG_FILE>\" } } The following rules apply: The types used in the description: <GENERIC_KEY_VALUE_PAIRS> are the key-value pairs discussed in the Formal definition of the generic configuration chapter <CONFIG_FILE> is a string You must assign a patterns config file for each configID by defining the patternsPath key If the configId contains virtual address spaces, you must assign a config file describing them by defining virtualSectionsPath key The assigned config files have to be in the same folder as the globalConfig.json The config files don't need to be different for each configID (for example you can use the same virtual sections config file for all the configIDs) patterns*.json \u00b6 The patterns config files define regex patterns for finding the mapfiles, monolith files and processing their content. They belong to the configID they were assigned to in the globalConfigs.json . These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"mapfiles\" : { \"<SW_NAME>\" : { \"regex\" : [ \"<REGEX_PATTERN>\" , ... \"<REGEX_PATTERN>\" ], \"VAS\" : \"<VAS_NAME>\" , \"UniquePatternSections\" : \"<REGEX_PATTERN>\" , \"UniquePatternObjects\" : \"<REGEX_PATTERN>\" , \"memRegionExcludes\" : [ \"<MEMORY_AREA>\" , ... \"<MEMORY_AREA>\" ] }, . . . \"<SW_NAME>\" : { \"regex\" : [ \"<REGEX_PATTERN>\" , ... \"<REGEX_PATTERN>\" ], \"VAS\" : \"<VAS_NAME>\" , \"UniquePatternSections\" : \"<REGEX_PATTERN>\" , \"UniquePatternObjects\" : \"<REGEX_PATTERN>\" , \"memRegionExcludes\" : [ \"<MEMORY_AREA>\" , ... \"<MEMORY_AREA>\" ] }, }, \"monoliths\" : { \"<MONILITH_NAME>\" : { \"regex\" : [ \"<REGEX_PATTERN>\" , ... \"<REGEX_PATTERN>\" ] } } } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <SW_NAME> is a string containing a unique name <REGEX_PATTERN> is a string containing a regex pattern following the format used by the \"re\" Python library <VAS_NAME> is a string <MONOLITH_NAME> is a string containing a unique name The mapfiles object must be present in the file with at least one entry: Each entry describes a SW unit of the configId (eg. a bootloader or application if an MCU is used or a process if an OS, like Linux is used): The regex defines one ore more regex pattern to find the mapfile that contains the data for this SW unit: It is possible to give more than one regex patterns in case of non-uniform mapfile names If more than one map file will be found for the SW unit, a warning will be thrown The search will be done in the mapfile folder defined by the command line arguments The VAS is optional element, defining the name of the virtual address space of this SW unit It is only required if the SW unit has entries that belong to virtual address spaces More than one mapfiles can contain data belonging to one virtual address space, so the VAS name does not need to be unique The UniquePatternSections is an optional element defining a regex pattern for collecting the sections from the mapfile It only needs to be defined if the default regex pattern has to be overridden This can be necessary if the toolchain where the mapfile coming from, produces another format The UniquePatternObjects is an optional element defining a regex pattern for collecting the objects from the mapfile It only needs to be defined if the default regex pattern has to be overridden This can be necessary if the toolchain where the mapfile coming from, produces another format The memRegionExcludes lists the memory areas that needs to be ignored during the analysis of the mapfile The sections and objects of the mapfile that belong to the memory areas listed here will be ignored The memory areas can be selected from the elements defined in the \"memory\" object of address spaces config file The monoliths object is optional, it is only needed if the configId has virtual address spaces If one the of the mapfiles object has a VAS key, then a monolith is needed It is possible to give more than one regex patterns in case of non-uniform monolith file names If more than one monolith file will be found for the SW unit, a warning will be thrown The search will be done in the mapfile folder defined by the command line arguments virtualSections*.json \u00b6 The virtual sections config files are used to assign the sections of the virtual address spaces to a virtual address spaces defined in the patterns*.json file. This is needed because the mapfiles can contain physical and virtual sections as well and Emma needs to identify the virtual ones and assign them to a specific virtual address space. If your configuration does not use virtual address spaces, the virtualSections*.json file is not needed. This config file have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"<VAS_NAME>\" : [ \"<SECTION_NAME>\" , . . . \"<SECTION_NAME>\" ], ... \"<VAS_NAME>\" : [ \"<SECTION_NAME>\" , . . . \"<SECTION_NAME>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <VAS_NAME> is a string <SECTION_NAME> is a string The <VAS_NAME> keys are the ones that were defined in the patterns*.json Every <VAS_NAME> key has an array as value that lists the sections that belong to the virtual address space There are no rules for the assignment, this needs to be done intuitively based on the project being analyzed Output Files \u00b6 The output Files will be saved to the memStats folder of the respective project. The filename will have this form: 1 2 3 <PROJECT_NAME>_Section_Summary_TIMESTAMP.csv <PROJECT_NAME>_Object_Summary_TIMESTAMP.csv <PROJECT_NAME>_Objects_in_Sections_TIMESTAMP.csv Section Summary \u00b6 The file <PROJECT_NAME>_Section_Summary_<TIMESTAMP>.csv contains the sections from the mapfiles. Object Summary \u00b6 The file <PROJECT_NAME>_Object_Summary_<TIMESTAMP>.csv contains the objects from the mapfiles. Objects in Sections \u00b6 \"Objects in sections\" provides ways to obtain a finer granularity of the categorisation result. Therefore categorised sections containing (smaller) objects of a different category got split up and result into a more accurate categorisation. As a result you will get output files in form of a .csv file which sets you up to do later processing on this data easily. In this file additional information is added like: Overlaps (of sections/objects) Containments (e.g. sections containing objects) Duplicates All meta data about the origin of each section/object (mapfile, addess space, ...) ... The file <PROJECT_NAME>_Objects_in_Sections_<TIMESTAMP>.csv is the result of the \"merge\" of the objects and the sections file. Objects/sections that are \"touching\" or overlapping each other in some way (see the above figure) are resolved in this step. Therefore the \"weaker\" section/object is split (and has therefore a reduced by size after each step). This is done so that the file represents a continuous and refined memory mapping. Furthermore it is checked whether sections/objects overlap, contain or duplicate each other. The information on such occurrences can be observed in the rightmost columns: overlapFlag : Overlaps with the stated section (\"overlapped by X\" means X is an object/section which has a lower start address and therefore overlaps the current element) containmentFlag : Is contained by the stated section duplicateFlag : Duplicate entry containgOthers : Contains stated sections/objects addrStartHexOriginal : Address before correction (in contrast to the \"new\" addresses due to the above actions) addrEndHexOriginal : Address before correction (in contrast to the \"new\" addresses due to the above actions) The above figure also shows how sizes of objects/sections are calculated correctly (-> namely: start - end + 1 ). Besides this a specific case of an overlap is shown above. A section/object having the same end address like the start address of another section/object. This happens to be already an overlap of one byte. As a result you see the + 1 addition for the size calculation. This might sound counter-intuitive at the first spot. However we can see memory addresses as memory blocks itself rather than infinitesimal barriers (what the term start and end address would intuitively suggest by its name). At the end you will find three remaining \"types\": Real objects: (Un)modified objects due to the above actions Section reserves: Resolved sections minus resolved objects; this is what remains when you resolve all \"touching\" occurrences and subtract objects from sections that we obtain (multiple) smaller sections Section entry: The original section size (without any modification); this is a pure virtual entry and has a size of 0 bytes; these are the only 0 byte sections which are a result of the Emma processing Section names for section reserves and entries are <Emma_SectionReserve> and <Emma_SectionEntry> respectively. The <Emma_xxxx> pattern shows you names introduced by Emma. CSV header \u00b6 The CSV file has the following columns: The address start, end and sizes: addrStartHex; addrEndHex; sizeHex; addrStartDec; addrEndDec; sizeDec; sizeHumanReadable The section and object name: sectionName; moduleName Note: If the image summary contains only sections, the column moduleName will be left empty. configID , memType and tag are from the config files. vasName is the virtual address space name defined in sections.json. The DMA field indicates whether a section/object is in a VAS. category : The category evaluated from categories*.json mapfile : The mapfile, the entry originates from. overlapFlag : Indicates whether one section overlaps with another. containmentFlag : Indicates whether a section is contained in another. duplicateFlag : Indicates whether a section has duplicates. Terminology \u00b6 In places there is some specific terminology used which is explained in the following chapter: DMA: Direct Memory Addressing; addresses which do not have to be translated (from virtual to physical); this has nothing to do with direct access to memory on the target (by bypassing the CPU core(s)) Emma was formerly known as MAdZ Examples \u00b6 Create a Mapfile Summary for : 1 2 3 Emma.py a --project .. \\< PROJECT> \\ --mapfiles .. \\M yMapfiles \\ --dir .. \\M yMapfiles \\r esults Matching object name and category using categoriesKeywords.json \u00b6 categoriesObjectsKeywords.json can be used to match object names with catgories by user defined keywords. Arguments required: --create_categories This step will append the newly categorised modules to categories.json . The program will ask you to confirm to overwrite the file. Removing not needed object names from categoriesObjects.json \u00b6 Not needed object names can be removed from categoriesObjects.json , for example when categoriesObjects.json from another project is used. Arguments required: --remove_unmatched This step will remove never matching object names from categoriesObjects.json . Some modules never match because e.g. the object got removed or is not present in the current release. The program will ask you to confirm to overwrite the file. General Information About Map Files and Build Chains \u00b6 COMPILER, ASSEMBLER, LINKER AND LOADER: A BRIEF STORY Hello World: C, Assembly, Object File and Executable Analyzing the Linker Map file with a little help from the ELF and the DWARF Anatomy of a Program in Memory Memory Management: Paging Beginner's Guide to Linkers Linker Scripts Technical Details \u00b6 GHS Monolith file generation \u00b6 Execute this to generate the monolith files (you need to have the ELF file for this step). 1 2 gdump.exe -virtual_mapping -no_trunc_sec_names Application.elf >> monolith.map gdump.exe -map -no_trunc_sec_names Application.elf >> monolith.map By default long names will be truncated. This can lead to inaccurate results. In order to prevent this use -no_trunc_sec_names . Class diagram Emma \u00b6 Calling Graph Emma \u00b6","title":"Emma"},{"location":"readme-emma.html#emma","text":"Emma Memory and Mapfile Analyser Conduct static (i.e. worst case) memory consumption analyses based on linker map files (currently only Green Hills map files are supported). This tool creates a summary/overview about static memory usage in form of a comma separated values (CSV) file.","title":"Emma"},{"location":"readme-emma.html#requirements","text":"Python 3.6 or higher Python libraries pypiscout 2.0 or higher: ( pip3 install pypiscout ) Tested on Windows and Linux systems","title":"Requirements"},{"location":"readme-emma.html#process","text":"Using the Mapfile Analyser is a two step process. The first step is to extract the required information from the mapfiles and save it to .csv files. This is done with the Emma.py a script. The second step is to visualise the data. This document explains the first part only, the visualisation is documented in the Emma visualiser readme document.","title":"Process"},{"location":"readme-emma.html#limitations","text":"The Emma is only suitable for analyzing projects where the devices have a single linear physical address space: Devices that use for example the Intel 8051 architecture have separate code and data address spaces that both start at address 0x0000. Devices based on architectures like this can not be analyzed with Emma. Devices that use for example the ARMv6M architecture have a single linear address space. Devices based on architectures like this can be analyzed with Emma.","title":"Limitations"},{"location":"readme-emma.html#arguments","text":"","title":"Arguments"},{"location":"readme-emma.html#required-arguments","text":"1 2 3 --project PROJECT, -p PROJECT --mapfiles MAPFILES, --map MAPFILES","title":"Required Arguments"},{"location":"readme-emma.html#optional-arguments","text":"--dir User defined path for the top folder holding the memStats /output files. Per default it uses the same directory as the config files. --stats_dir User defined path inside the folder given in the --dir argument. This is usefull when batch analysing mapfiles from various development stages. Every analysis output gets it's own directory. --create_categories Create categories*.json from categories*Keywords.json for easier categorisation. --remove_unmatched , Remove unmatched entries from categories*.json . This is useful when a categories*.json from another project is used. --analyse_debug , --dbg Normally we remove DWARF debug sections from the analysis to show the relevant information for a possible release software. This can be prevented if this argument is set. DWARF section names are defined in stringConstants.py . .unused_ram is always excluded (regardless of this flag) --noprompt Exit and fail on user prompt. Normally this happens when some files or configurations are ambiguous. This is useful when running Emma on CI systems.","title":"Optional Arguments"},{"location":"readme-emma.html#project-configuration","text":"The memory analysis will be executed based on the project configuration. In order to be able to use Emma with your project, you need to create a configuration matching your project's hardware and software. Configure Emma with high diligence since errors may lead to incorrect results of your analysis . During the analysis Emma performs some sanity checks which helps you detecting misconfiguration. This chapter explains the role and functionality of each part of the configuration and illustrates all the settings that can be used. Based on this description the user will have to create his/her own configuration. Creating a configuration is done by writing several JSON files (if you are not familiar with JSON, please visit https://www.json.org ). This chapter will go trough the topic by formally defining the format, rules and the functionality of the config files. There are practical example projects available in the doc folder. These projects will lead you step by step trough the process of creating a configuration and they also contain map files that can be analyzed. Currently the following example projects are available: doc/test_project - A project that illustrates a system with a hardware that consists of two devices: an MCU and an SOC. Both of the devices have a GHS compiler specific configuration and mapfiles. An Emma project configuration consists of two parts: the generic configuration and the compiler specific configuration.","title":"Project Configuration"},{"location":"readme-emma.html#formal-definition-of-the-generic-configuration","text":"The generic part of the configuration contains the following files: 1 2 3 4 5 6 7 8 9 10 + -- [<PROJECT>] | + -- [supplement] | + -- globalConfig.json | + -- addressSpaces*.json | + -- budgets.json | + -- categoriesObjects.json | + -- categoriesObjectsKeywords.json | + -- categoriesSections.json | + -- categoriesSectionsKeywords.json | + -- <COMPILER_SPECIFIC_CONFIGURATION_FILES> The files containing the asterisk symbol can be freely named by the user because the actual file names will have to be listed in the globalConfig.json.","title":"Formal definition of the generic configuration"},{"location":"readme-emma.html#project","text":"The configuration has to be contained by a folder. The name of the folder will be the name of the configuration. From the files ending with a * symbol, the configuration can contain more than one but maximum up to the number of configIDs defined in globalConfig.json.","title":"PROJECT"},{"location":"readme-emma.html#supplement","text":"You can add .md files into this folder with Markdown syntax to add information regarding your project that will be contained by the .html overview. For more information please refer to the Emma Visualiser's documentation.","title":"supplement"},{"location":"readme-emma.html#globalconfigjson","text":"The globalConfig.json is the starting point of a configuration, this file defines the configId -s. The configId-s are the hardware units of the system that have memory associated to them, for example an MCU, MPU or an SOC. During the analysis, it will be examined to which extent these memory resources are used. For each configId, globalConfig.json assigns a compiler. This means that the mapfiles belonging to the configId were created by the selected compiler. This is important, since the format of these files are specific to the compiler. For each configId an addressSpaces*.json config file will be assigned. Furthermore the globalConfig.json assigns compiler specific config files to each configId, that need to be consistent with the selected compiler. For example if a GHS compiler was selected to the configId, then the compiler specific configuration part of this configId have to fulfill the requirements described in the Formal Definition of the GHS compiler specific configuration chapter. The globalConfig.json has to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"<CONFIG_ID>\" : { \"compiler\" : \"<COMPILER_NAME>\" , \"addressSpacesPath\" : \"<CONFIG_FILE>\" , \"mapfiles\" : \"<MAPFILES_REL_PATH>\" , \"ignoreConfigID\" : \"<BOOL>\" , <COMPILER_SPECIFIC_KEY_VALUE_PAIRS> }, . . . \"<CONFIG_ID>\" : { \"compiler\" : \"<COMPILER_NAME>\" , \"addressSpacesPath\" : \"<CONFIG_FILE>\" , \"mapfiles\" : \"<MAPFILES_REL_PATH>\" , \"ignoreConfigID\" : \"<BOOL>\" , <COMPILER_SPECIFIC_KEY_VALUE_PAIRS> } } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <CONFIG_ID> is a string <COMPILER_NAME> is a string <CONFIG_FILE> is a string <MAPFILES_REL_PATH> is a string, with the special characters escaped in it <BOOL> is a boolean value containing either true or false <COMPILER_SPECIFIC_KEY_VALUE_PAIRS> are the key-value pairs that are required by the selected compiler There has to be at least one configID defined You must select a compiler for every configID, by defining the compiler key. The possible values are: \"GHS\" - Green Hills Compiler You must assign the following config files for each configID by defining the following key, value pairs: by defining addressSpacesPath , the config file that defines the address spaces is assigned The config files have to be in the same folder as the globalConfig.json The config files don't need to be different for each configID (for example you can use the same address spaces config file for all the configIDs) The mapfiles: specifies a folder relative to the one given via --mapfiles command line argument is optional, if is defined for a configID, then the map files belonging to this configId will be searched for within this folder Otherwise the mapfiles will be searched for in the --mapfiles root map file path The ignoreConfigID: can be used to mark a configID as ignored, which means that this will not be processed during the analysis is optional, it does not need to be included in every configID, leaving it has the same effect as including it with false","title":"globalConfig.json"},{"location":"readme-emma.html#addressspacesjson","text":"The address spaces config files define the existing memory areas for the configIDs they were assigned to in the globalConfigs.json. These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"offset\" : \"<ADDRESS>\" , \"memory\" : { \"<MEMORY_AREA>\" : { \"start\" : \"<ADDRESS>\" , \"end\" : \"<ADDRESS>\" , \"type\" : \"<MEMORY_TYPE>\" }, . . . \"<MEMORY_AREA>\" : { \"start\" : \"<ADDRESS>\" , \"end\" : \"<ADDRESS>\" , \"type\" : \"<MEMORY_TYPE>\" } }, \"ignoreMemory\" : [ \"<MEMORY_AREA>\" , ... \"<MEMORY_AREA>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <ADDRESS> is a string containing a 64bit hexadecimal value, for example \"0x1FFFFFFF\" <MEMORY_AREA> is a string containing a unique name <MEMORY_TYPE> is a string containing one of the following values: \"INT_RAM\" - internal RAM \"EXT_RAM\" - external RAM \"INT_FLASH\" - internal Flash \"EXT_FLASH\" - external Flash The offset is a global address offset applied to all addresses in the file memory is a JSON object that defines the memory areas Each memory area is a JSON object that has three elements: start - start address end - end address type - memory type The ignoreMemory is a JSON array used to mark one or more <MEMORY_AREA> to be ignored during the analysis: The the elements of this array can be selected from the ones defined in the \"memory\" object It is optional, not including it or including it as an empty array means none of the <MEMORY_AREA> s are ignored","title":"addressSpaces*.json"},{"location":"readme-emma.html#budgetsjson","text":"The budgets config file belongs to the Emma Visualiser. For a description, please see: doc/readme-vis.md .","title":"budgets.json"},{"location":"readme-emma.html#categoriesobjectsjson-and-categoriessectionsjson","text":"The categories config files are used to categorize objects and sections to user defined categories by using their full names. These files are optional, if no categorization needed, these config files do not need to be created. This function can be used for example to group the software components of one company together which will make the results easier to understand. The categoriesObjects.json is used for the objects and the categoriesSections.json is used for the section categorization. The objects and sections will be first tried to be categorized by these files. If they could not be categorized, then the software will try to categorize them based on the categoriesObjectsKeywords.json and categoriesSectionsKeywords.json files. These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"<CATEGORY>\" : [ \"<NAME>\" , . . . \"<NAME>\" ], . . . \"<CATEGORY>\" : [ \"<NAME>\" , . . . \"<NAME>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <CATEGORY> is a string containing a unique category name <NAME> is a string The categorisation can be done either by hand or with the --create_categories command line argument (for usage see there) The <NAME> has to contain full names of the sections or objects","title":"categoriesObjects.json and categoriesSections.json"},{"location":"readme-emma.html#categoriesobjectskeywordsjson-and-categoriessectionskeywordsjson","text":"The categories keywords config files are used to categorize objects and sections to user defined categories by using only substrings of their names. These files are optional, if no categorization needed, these config files do not need to be created. This function can be used for example to group the software components of one company together which will make the results easier to understand. The categoriesObjectsKeywords.json is used for the objects and the categoriesSectionsKeywords.json is used for the section categorization. The objects and sections will only tried to be categorized by these files if the categorization by the categoriesObjects.json and categoriesSections.json files failed. If they could not be categorized, then the software will assign them to a category called <Emma_UnknownCategory> so they will be more visible in the results. These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"<CATEGORY>\" : [ \"<KEYWORD>\" , . . . \"<KEYWORD>\" ], \"<CATEGORY>\" : [ \"<KEYWORD>\" , . . . \"<KEYWORD>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <CATEGORY> is a string containing a unique category name <KEYWORD> is a string The categorisation has to be done by hand The <KEYWORD> contains a regex pattern for the names of the sections or objects","title":"categoriesObjectsKeywords.json and categoriesSectionsKeywords.json"},{"location":"readme-emma.html#formal-definition-of-the-ghs-compiler-specific-configuration","text":"The GHS compiler specific part of the configuration contains the following files: 1 2 3 4 + -- [<PROJECT>] | + -- <GENERIC_CONFIGURATION_FILES> | + -- patterns*.json | + -- virtualSections*.json The following dependencies exist within this type of a configuration: In globalConfig.json , you need to reference (ref relations on the picture): addressSpaces*.json patterns*.json sections*.json memRegionExcludes : You can exclude certain memory regions with this keyword in patterns*.json . In order to do this the memory regions/tags must match with those defined in addressSpaces*.json . If you have virtual address spaces (VASes) defined. You need a \"monolith file\" pattern defined in patterns*.json in order to be able to translate virtual addresses back to physical addresses. In the same file you give each VAS a name. This name is later used to identify which section belongs to which VAS (defined in virtualSections*.json ). The VAS names must match between those two files. This is needed in order to avoid name clashes of sections names between different VASes.","title":"Formal Definition of the GHS compiler specific configuration"},{"location":"readme-emma.html#extensions-to-the-globalconfigjson","text":"The globalConfig.json has to have the following format for configId-s that have selected \"GHS\" as compiler : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \"<CONFIG_ID>\" : { <GENERIC_KEY_VALUE_PAIRS>, \"patternsPath\" : \"<CONFIG_FILE>\" , \"virtualSectionsPath\" : \"<CONFIG_FILE>\" }, . . . \"<CONFIG_ID>\" : { <GENERIC_KEY_VALUE_PAIRS>, \"patternsPath\" : \"<CONFIG_FILE>\" , \"virtualSectionsPath\" : \"<CONFIG_FILE>\" } } The following rules apply: The types used in the description: <GENERIC_KEY_VALUE_PAIRS> are the key-value pairs discussed in the Formal definition of the generic configuration chapter <CONFIG_FILE> is a string You must assign a patterns config file for each configID by defining the patternsPath key If the configId contains virtual address spaces, you must assign a config file describing them by defining virtualSectionsPath key The assigned config files have to be in the same folder as the globalConfig.json The config files don't need to be different for each configID (for example you can use the same virtual sections config file for all the configIDs)","title":"Extensions to the globalConfig.json"},{"location":"readme-emma.html#patternsjson","text":"The patterns config files define regex patterns for finding the mapfiles, monolith files and processing their content. They belong to the configID they were assigned to in the globalConfigs.json . These config files have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"mapfiles\" : { \"<SW_NAME>\" : { \"regex\" : [ \"<REGEX_PATTERN>\" , ... \"<REGEX_PATTERN>\" ], \"VAS\" : \"<VAS_NAME>\" , \"UniquePatternSections\" : \"<REGEX_PATTERN>\" , \"UniquePatternObjects\" : \"<REGEX_PATTERN>\" , \"memRegionExcludes\" : [ \"<MEMORY_AREA>\" , ... \"<MEMORY_AREA>\" ] }, . . . \"<SW_NAME>\" : { \"regex\" : [ \"<REGEX_PATTERN>\" , ... \"<REGEX_PATTERN>\" ], \"VAS\" : \"<VAS_NAME>\" , \"UniquePatternSections\" : \"<REGEX_PATTERN>\" , \"UniquePatternObjects\" : \"<REGEX_PATTERN>\" , \"memRegionExcludes\" : [ \"<MEMORY_AREA>\" , ... \"<MEMORY_AREA>\" ] }, }, \"monoliths\" : { \"<MONILITH_NAME>\" : { \"regex\" : [ \"<REGEX_PATTERN>\" , ... \"<REGEX_PATTERN>\" ] } } } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <SW_NAME> is a string containing a unique name <REGEX_PATTERN> is a string containing a regex pattern following the format used by the \"re\" Python library <VAS_NAME> is a string <MONOLITH_NAME> is a string containing a unique name The mapfiles object must be present in the file with at least one entry: Each entry describes a SW unit of the configId (eg. a bootloader or application if an MCU is used or a process if an OS, like Linux is used): The regex defines one ore more regex pattern to find the mapfile that contains the data for this SW unit: It is possible to give more than one regex patterns in case of non-uniform mapfile names If more than one map file will be found for the SW unit, a warning will be thrown The search will be done in the mapfile folder defined by the command line arguments The VAS is optional element, defining the name of the virtual address space of this SW unit It is only required if the SW unit has entries that belong to virtual address spaces More than one mapfiles can contain data belonging to one virtual address space, so the VAS name does not need to be unique The UniquePatternSections is an optional element defining a regex pattern for collecting the sections from the mapfile It only needs to be defined if the default regex pattern has to be overridden This can be necessary if the toolchain where the mapfile coming from, produces another format The UniquePatternObjects is an optional element defining a regex pattern for collecting the objects from the mapfile It only needs to be defined if the default regex pattern has to be overridden This can be necessary if the toolchain where the mapfile coming from, produces another format The memRegionExcludes lists the memory areas that needs to be ignored during the analysis of the mapfile The sections and objects of the mapfile that belong to the memory areas listed here will be ignored The memory areas can be selected from the elements defined in the \"memory\" object of address spaces config file The monoliths object is optional, it is only needed if the configId has virtual address spaces If one the of the mapfiles object has a VAS key, then a monolith is needed It is possible to give more than one regex patterns in case of non-uniform monolith file names If more than one monolith file will be found for the SW unit, a warning will be thrown The search will be done in the mapfile folder defined by the command line arguments","title":"patterns*.json"},{"location":"readme-emma.html#virtualsectionsjson","text":"The virtual sections config files are used to assign the sections of the virtual address spaces to a virtual address spaces defined in the patterns*.json file. This is needed because the mapfiles can contain physical and virtual sections as well and Emma needs to identify the virtual ones and assign them to a specific virtual address space. If your configuration does not use virtual address spaces, the virtualSections*.json file is not needed. This config file have to have the following format: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"<VAS_NAME>\" : [ \"<SECTION_NAME>\" , . . . \"<SECTION_NAME>\" ], ... \"<VAS_NAME>\" : [ \"<SECTION_NAME>\" , . . . \"<SECTION_NAME>\" ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <VAS_NAME> is a string <SECTION_NAME> is a string The <VAS_NAME> keys are the ones that were defined in the patterns*.json Every <VAS_NAME> key has an array as value that lists the sections that belong to the virtual address space There are no rules for the assignment, this needs to be done intuitively based on the project being analyzed","title":"virtualSections*.json"},{"location":"readme-emma.html#output-files","text":"The output Files will be saved to the memStats folder of the respective project. The filename will have this form: 1 2 3 <PROJECT_NAME>_Section_Summary_TIMESTAMP.csv <PROJECT_NAME>_Object_Summary_TIMESTAMP.csv <PROJECT_NAME>_Objects_in_Sections_TIMESTAMP.csv","title":"Output Files"},{"location":"readme-emma.html#section-summary","text":"The file <PROJECT_NAME>_Section_Summary_<TIMESTAMP>.csv contains the sections from the mapfiles.","title":"Section Summary"},{"location":"readme-emma.html#object-summary","text":"The file <PROJECT_NAME>_Object_Summary_<TIMESTAMP>.csv contains the objects from the mapfiles.","title":"Object Summary"},{"location":"readme-emma.html#objects-in-sections","text":"\"Objects in sections\" provides ways to obtain a finer granularity of the categorisation result. Therefore categorised sections containing (smaller) objects of a different category got split up and result into a more accurate categorisation. As a result you will get output files in form of a .csv file which sets you up to do later processing on this data easily. In this file additional information is added like: Overlaps (of sections/objects) Containments (e.g. sections containing objects) Duplicates All meta data about the origin of each section/object (mapfile, addess space, ...) ... The file <PROJECT_NAME>_Objects_in_Sections_<TIMESTAMP>.csv is the result of the \"merge\" of the objects and the sections file. Objects/sections that are \"touching\" or overlapping each other in some way (see the above figure) are resolved in this step. Therefore the \"weaker\" section/object is split (and has therefore a reduced by size after each step). This is done so that the file represents a continuous and refined memory mapping. Furthermore it is checked whether sections/objects overlap, contain or duplicate each other. The information on such occurrences can be observed in the rightmost columns: overlapFlag : Overlaps with the stated section (\"overlapped by X\" means X is an object/section which has a lower start address and therefore overlaps the current element) containmentFlag : Is contained by the stated section duplicateFlag : Duplicate entry containgOthers : Contains stated sections/objects addrStartHexOriginal : Address before correction (in contrast to the \"new\" addresses due to the above actions) addrEndHexOriginal : Address before correction (in contrast to the \"new\" addresses due to the above actions) The above figure also shows how sizes of objects/sections are calculated correctly (-> namely: start - end + 1 ). Besides this a specific case of an overlap is shown above. A section/object having the same end address like the start address of another section/object. This happens to be already an overlap of one byte. As a result you see the + 1 addition for the size calculation. This might sound counter-intuitive at the first spot. However we can see memory addresses as memory blocks itself rather than infinitesimal barriers (what the term start and end address would intuitively suggest by its name). At the end you will find three remaining \"types\": Real objects: (Un)modified objects due to the above actions Section reserves: Resolved sections minus resolved objects; this is what remains when you resolve all \"touching\" occurrences and subtract objects from sections that we obtain (multiple) smaller sections Section entry: The original section size (without any modification); this is a pure virtual entry and has a size of 0 bytes; these are the only 0 byte sections which are a result of the Emma processing Section names for section reserves and entries are <Emma_SectionReserve> and <Emma_SectionEntry> respectively. The <Emma_xxxx> pattern shows you names introduced by Emma.","title":"Objects in Sections"},{"location":"readme-emma.html#csv-header","text":"The CSV file has the following columns: The address start, end and sizes: addrStartHex; addrEndHex; sizeHex; addrStartDec; addrEndDec; sizeDec; sizeHumanReadable The section and object name: sectionName; moduleName Note: If the image summary contains only sections, the column moduleName will be left empty. configID , memType and tag are from the config files. vasName is the virtual address space name defined in sections.json. The DMA field indicates whether a section/object is in a VAS. category : The category evaluated from categories*.json mapfile : The mapfile, the entry originates from. overlapFlag : Indicates whether one section overlaps with another. containmentFlag : Indicates whether a section is contained in another. duplicateFlag : Indicates whether a section has duplicates.","title":"CSV header"},{"location":"readme-emma.html#terminology","text":"In places there is some specific terminology used which is explained in the following chapter: DMA: Direct Memory Addressing; addresses which do not have to be translated (from virtual to physical); this has nothing to do with direct access to memory on the target (by bypassing the CPU core(s)) Emma was formerly known as MAdZ","title":"Terminology"},{"location":"readme-emma.html#examples","text":"Create a Mapfile Summary for : 1 2 3 Emma.py a --project .. \\< PROJECT> \\ --mapfiles .. \\M yMapfiles \\ --dir .. \\M yMapfiles \\r esults","title":"Examples"},{"location":"readme-emma.html#matching-object-name-and-category-using-categorieskeywordsjson","text":"categoriesObjectsKeywords.json can be used to match object names with catgories by user defined keywords. Arguments required: --create_categories This step will append the newly categorised modules to categories.json . The program will ask you to confirm to overwrite the file.","title":"Matching object name and category using categoriesKeywords.json"},{"location":"readme-emma.html#removing-not-needed-object-names-from-categoriesobjectsjson","text":"Not needed object names can be removed from categoriesObjects.json , for example when categoriesObjects.json from another project is used. Arguments required: --remove_unmatched This step will remove never matching object names from categoriesObjects.json . Some modules never match because e.g. the object got removed or is not present in the current release. The program will ask you to confirm to overwrite the file.","title":"Removing not needed object names from categoriesObjects.json"},{"location":"readme-emma.html#general-information-about-map-files-and-build-chains","text":"COMPILER, ASSEMBLER, LINKER AND LOADER: A BRIEF STORY Hello World: C, Assembly, Object File and Executable Analyzing the Linker Map file with a little help from the ELF and the DWARF Anatomy of a Program in Memory Memory Management: Paging Beginner's Guide to Linkers Linker Scripts","title":"General Information About Map Files and Build Chains"},{"location":"readme-emma.html#technical-details","text":"","title":"Technical Details"},{"location":"readme-emma.html#ghs-monolith-file-generation","text":"Execute this to generate the monolith files (you need to have the ELF file for this step). 1 2 gdump.exe -virtual_mapping -no_trunc_sec_names Application.elf >> monolith.map gdump.exe -map -no_trunc_sec_names Application.elf >> monolith.map By default long names will be truncated. This can lead to inaccurate results. In order to prevent this use -no_trunc_sec_names .","title":"GHS Monolith file generation"},{"location":"readme-emma.html#class-diagram-emma","text":"","title":"Class diagram Emma"},{"location":"readme-emma.html#calling-graph-emma","text":"","title":"Calling Graph Emma"},{"location":"readme-vis.html","text":"Emma Visualiser \u00b6 Emma Memory and Mapfile Analyser Visualiser Data aggregation and visualisation tool for Emma. Requirements \u00b6 Python 3.6 or higher Python libraries pypiscout 2.0 or higher: ( pip3 install pypiscout ) Pandas 0.22 or higher: ( pip3 install pandas ) Matplotlib 2.2.0 or higher: ( pip3 install matplotlib ) Markdown 3.0.1 or higher: ( pip3 install Markdown ) Pygments 2.3.1 or higher: ( pip3 install Pygments ) Tested on Windows and Linux systems Process \u00b6 After analysing the mapfiles with the Emma.py a script one can visualise them using Emma.py v . Arguments in detail \u00b6 Optional Arguments \u00b6 --inOutDir INOUTDIR, -i INOUTDIR --subDir SUBDIR User defined path for the folder ./memStats holding generated statistics from Emma. If not specified the schema below will be followed: Argument -> --projectDir --inOutDir --subDir I/O path Given? x projectDir Given? x x inOutDir Given? x x x join(inOutDir + subDir) I/O path denotes the path containing memStats . In the same path the results folder will be created. By defining SUBDIR a folder with the given name is created in the results directory. This option makes it easier to distinguish between different development stages when batch analysing mapfiles. --append Additional reports in .csv format will be created in the ./results directory. --categorised_image_csv, -cat_img Save a .csv of categories found inside the image summary (default: False). Quiet Mode \u00b6 --quiet, -q Automatically accepts last modified .csv file in ./memStats folder (default: False). If not specified the program will ask you to confirm the default path if not given or ambiguous. Overview \u00b6 --overview This creates a .md and .html output containing an overview of the memory usage. Append Mode \u00b6 --append Appends analyses to .csv files. This can be used to visualise memory usage over different versions. Project Configuration \u00b6 There are several configuration files needed in order to analyze your project. Most of them are described in the Emma documentation. Here, only the ones described that are used by the Emma Visualiser exclusively. budgets.json \u00b6 This config file is used to define the available memory for every memory area of every configID. Besides this it defines a threshold value as well that will be displayed on the diagrams. This threshold can be for example prescribed by your project requirements in order to ensure there will be available memory areas for future updates. The config file needs to have the following format: 1 2 3 4 5 6 7 8 9 10 11 { \"Project Threshold in %\" : <THRESHOLD_VALUE> , \"Budgets\" : [ [ \"<CONFIG_ID>\" , \"<MEMORY_TYPE>\" , <AVAILABLE_MEMORY> ], . . . [ \"<CONFIG_ID>\" , \"<MEMORY_TYPE>\" , <AVAILABLE_MEMORY> ] ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <THRESHOLD_VALUE> is an integer <CONFIG_ID> is a string <MEMORY_TYPE> is a string containing one of the following values: \"INT_RAM\" - internal RAM \"EXT_RAM\" - external RAM \"INT_FLASH\" - internal Flash \"EXT_FLASH\" - external Flash <AVAILABLE_MEMORY> is an integer The <THRESHOLD_VALUE> defines the project in percents The \"Budgets\" array has to contain a line for every <MEMORY_TYPE> of every <CONFIG_ID> The <CONFIG_ID> s are the ones defined in the globalConfig.json (See the Emma documentation for details) The <AVAILABLE_MEMORY> s are defining the available memory for a <MEMORY_TYPE> of a <CONFIG_ID> in bytes [supplement] \u00b6 .md files in this directory will be appended to the report created by the --overview command. This can be used to append additional remarks to the overview. This is completely user defined, Emma and its components are not relying on these files in any way. Input/Output Files \u00b6 All output files will be saved to ./[PROJECT]/results . If not specified otherwise using the --quiet and --inOutDir commands, the visualiser will choose the last modified section and object summary .csv files in the ./[PROJECT]/memStats directory. If there is no module summary present the visualisation of the modules will be skipped. Output files are: .png 's of all plots Overview mode creates .md and .html files of the overview A .csv file showing which section contains which modules Examples \u00b6 After the Image Summary has been created with Emma.py a and the memStats CSV files were saved to the directory ../[PROJECT]/results/memStats , it can be visualised using: 1 python Emma.py v --project .. \\< PROJECT> --dir .. \\[ PROJECT ] \\r esults --quiet --overview Calling Graph Emma Visualiser \u00b6","title":"Emma Visualiser"},{"location":"readme-vis.html#emma-visualiser","text":"Emma Memory and Mapfile Analyser Visualiser Data aggregation and visualisation tool for Emma.","title":"Emma Visualiser"},{"location":"readme-vis.html#requirements","text":"Python 3.6 or higher Python libraries pypiscout 2.0 or higher: ( pip3 install pypiscout ) Pandas 0.22 or higher: ( pip3 install pandas ) Matplotlib 2.2.0 or higher: ( pip3 install matplotlib ) Markdown 3.0.1 or higher: ( pip3 install Markdown ) Pygments 2.3.1 or higher: ( pip3 install Pygments ) Tested on Windows and Linux systems","title":"Requirements"},{"location":"readme-vis.html#process","text":"After analysing the mapfiles with the Emma.py a script one can visualise them using Emma.py v .","title":"Process"},{"location":"readme-vis.html#arguments-in-detail","text":"","title":"Arguments in detail"},{"location":"readme-vis.html#optional-arguments","text":"--inOutDir INOUTDIR, -i INOUTDIR --subDir SUBDIR User defined path for the folder ./memStats holding generated statistics from Emma. If not specified the schema below will be followed: Argument -> --projectDir --inOutDir --subDir I/O path Given? x projectDir Given? x x inOutDir Given? x x x join(inOutDir + subDir) I/O path denotes the path containing memStats . In the same path the results folder will be created. By defining SUBDIR a folder with the given name is created in the results directory. This option makes it easier to distinguish between different development stages when batch analysing mapfiles. --append Additional reports in .csv format will be created in the ./results directory. --categorised_image_csv, -cat_img Save a .csv of categories found inside the image summary (default: False).","title":"Optional Arguments"},{"location":"readme-vis.html#quiet-mode","text":"--quiet, -q Automatically accepts last modified .csv file in ./memStats folder (default: False). If not specified the program will ask you to confirm the default path if not given or ambiguous.","title":"Quiet Mode"},{"location":"readme-vis.html#overview","text":"--overview This creates a .md and .html output containing an overview of the memory usage.","title":"Overview"},{"location":"readme-vis.html#append-mode","text":"--append Appends analyses to .csv files. This can be used to visualise memory usage over different versions.","title":"Append Mode"},{"location":"readme-vis.html#project-configuration","text":"There are several configuration files needed in order to analyze your project. Most of them are described in the Emma documentation. Here, only the ones described that are used by the Emma Visualiser exclusively.","title":"Project Configuration"},{"location":"readme-vis.html#budgetsjson","text":"This config file is used to define the available memory for every memory area of every configID. Besides this it defines a threshold value as well that will be displayed on the diagrams. This threshold can be for example prescribed by your project requirements in order to ensure there will be available memory areas for future updates. The config file needs to have the following format: 1 2 3 4 5 6 7 8 9 10 11 { \"Project Threshold in %\" : <THRESHOLD_VALUE> , \"Budgets\" : [ [ \"<CONFIG_ID>\" , \"<MEMORY_TYPE>\" , <AVAILABLE_MEMORY> ], . . . [ \"<CONFIG_ID>\" , \"<MEMORY_TYPE>\" , <AVAILABLE_MEMORY> ] ] } The following rules apply: The file contains a single unnamed JSON object The types used in the description: <THRESHOLD_VALUE> is an integer <CONFIG_ID> is a string <MEMORY_TYPE> is a string containing one of the following values: \"INT_RAM\" - internal RAM \"EXT_RAM\" - external RAM \"INT_FLASH\" - internal Flash \"EXT_FLASH\" - external Flash <AVAILABLE_MEMORY> is an integer The <THRESHOLD_VALUE> defines the project in percents The \"Budgets\" array has to contain a line for every <MEMORY_TYPE> of every <CONFIG_ID> The <CONFIG_ID> s are the ones defined in the globalConfig.json (See the Emma documentation for details) The <AVAILABLE_MEMORY> s are defining the available memory for a <MEMORY_TYPE> of a <CONFIG_ID> in bytes","title":"budgets.json"},{"location":"readme-vis.html#supplement","text":".md files in this directory will be appended to the report created by the --overview command. This can be used to append additional remarks to the overview. This is completely user defined, Emma and its components are not relying on these files in any way.","title":"[supplement]"},{"location":"readme-vis.html#inputoutput-files","text":"All output files will be saved to ./[PROJECT]/results . If not specified otherwise using the --quiet and --inOutDir commands, the visualiser will choose the last modified section and object summary .csv files in the ./[PROJECT]/memStats directory. If there is no module summary present the visualisation of the modules will be skipped. Output files are: .png 's of all plots Overview mode creates .md and .html files of the overview A .csv file showing which section contains which modules","title":"Input/Output Files"},{"location":"readme-vis.html#examples","text":"After the Image Summary has been created with Emma.py a and the memStats CSV files were saved to the directory ../[PROJECT]/results/memStats , it can be visualised using: 1 python Emma.py v --project .. \\< PROJECT> --dir .. \\[ PROJECT ] \\r esults --quiet --overview","title":"Examples"},{"location":"readme-vis.html#calling-graph-emma-visualiser","text":"","title":"Calling Graph Emma Visualiser"},{"location":"test_project/readme.html","text":"Test Project \u00b6 This is an imaginary system, the mapfiles were created by hand and they are following the default Emma mapfile format. The goal of the project is to present a simple system without any complicated parts in order to introduce the new users step-by-step to creating an Emma configuration. The project can be analyzed by running the following commands from the Emma top-level folder: Emma: 1 python Emma.py a --project doc/test_project --mapfiles doc/test_project/mapfiles Emma Visualier: 1 python Emma.py v --project doc/test_project --dir doc/test_project/results --overview --quiet The folder structure of the Test Project: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 +--[test_project] | +-- [mapfiles] # The mapfiles of the project are stored here | +-- [readme] # The folder of this description | +-- [results] # The results of the analyse will be stored here by the commands above | +-- [supplement] # Supplements to the result overview (see Emma Visualiser documentation) | +-- globalConfig.json | +-- addressSpaces_MCU.json | +-- addressSpaces_SOC.json | +-- patterns_MCU.json | +-- patterns_SOC.json | +-- virtualSections_SOC.json | +-- categoriesObjects.json | +-- categoriesSections.json | +-- categoriesObjectsKeywords.json | +-- categoriesSectionsKeywords.json Project description \u00b6 The project illustrates a system with a hardware that consists of two devices: an MCU and an SOC. MCU \u00b6 The MCU software consists of two firmware, the application and the bootloader. Both of them are loaded into the internal Flash, but they are never running at the same time. They share the same stack area and none of them have a heap. Besides the internal Flash and RAM available on the MCU, there is an external Flash available trough SPI for the software to use. After a system start-up, the execution will be given to the Bootloader. The function of the bootloader is to check version number and the CRC value of the application firmware and in case an update is needed, (newer firmware available or CRC error of the current one) try to update it. The firmware for the update is stored in the external flash. The bootloader is a bare-metal firmware, it does not use an operating system. The function of the application is to load the parameter set from the external Flash memory and run a complex CAN stack. It implements a connection based protocol called CAN_PROT . The protocol makes the Application firmware able to receive a firmware update which will then be stored in the external Flash. After executing the reset command received trough the CAN stack, the Bootloader can flash the application if all the firmware checks pass. The application has a simple RTOS running on it called OS. The memory layout of the MCU: SOC \u00b6 The SOC is running a complex operating system that utilizes the memory management unit (MMU) of the processor. The software running on the SOC contains multiple virtual address spaces. Besides the operating system, there are two processes running on the chip: the NetLogger and the application. The NetLogger is a logging framework, trough which the software can be remotely monitored. The log messages are sent from other processes trough the IPC service provided by the operating system. These messages can be accessed and filtered by a remote client trough a TCP/IP connection. The application is handling a capacitive touchscreen trough the Gfx graphics library and other software components. It is presenting animations to the user, which he can control trough the touch screen. The application is creating log messages about every event that occurs trough the NetLog library. The NetLog library will transfer the log messages to the NetLogger framework if available on the system. The memory layout of the SOC: Creating the configuration \u00b6 This chapter will explain creating the configuration for the project by explaining every step the user should take. globalConfig.json \u00b6 Creating the project configuration starts with creating the globalConfig.json . This file lists the programmable devices of the system and assigns the further configuration files to configuration. We will add our two devices (MCU and SOC) as JSON objects. For every device, the used compiler and at least two config files must be assigned: the addressSpaces and the patterns. For devices using virtual address spaces, a third one, the sections is needed as well. As we are using Green Hills Compiler, so the mapfiles will be in this format, we will define the value GHS for both of the devices. Since in our system, we have different devices with different memory layout, we have assigned two different addressSpaces config files to them. If your system contains multiple devices of the same type, you can use the same addressSpaces config file for these devices. The patterns config file files are usually unique for all the configIDs. Since the MCU does not have an MMU so it does not have virtual address spaces, we will not assign a sections config file to it. In contrast to the MCU, the SOC does use virtual address spaces, so we will assign a sections config file to it. 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"MCU\" : { \"compiler\" : \"GHS\" , \"addressSpacesPath\" : \"addressSpaces_MCU.json\" , \"patternsPath\" : \"patterns_MCU.json\" }, \"SOC\" : { \"compiler\" : \"GHS\" , \"addressSpacesPath\" : \"addressSpaces_SOC.json\" , \"patternsPath\" : \"patterns_SOC.json\" , \"virtualSectionsPath\" : \"virtualSections_SOC.json\" } } In the following, the config files assigned to the MCU will be explained. addressSpaces_MCU.json \u00b6 In this config file, the memory areas of the MCU will be defined. You can collect information on them from the data sheet of the device. For every memory area, we have to define the start and end addresses in bytes and assign a type to it as well. For the possible values of the \"type\", see the Emma documentation. For the MCU used in the system, the following memory areas are available: Code , SRAM and Device . The Code area is an internal Flash area, where the program and the constants will be stored. The SRAM area is an internal RAM area, where data is stored. The last area is the Device , where the SFRs of the controller are located. Since our software will have neither data nor code in this area, we will add it to the ignoreMemory array so it will not be a analysed by Emma. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 { \"memory\" : { \"Code\" : { \"start\" : \"0x00000000\" , \"end\" : \"0x1FFFFFFF\" , \"type\" : \"INT_FLASH\" }, \"SRAM\" : { \"start\" : \"0x20000000\" , \"end\" : \"0x3FFFFFFF\" , \"type\" : \"INT_RAM\" }, \"Device\" : { \"start\" : \"0x40000000\" , \"end\" : \"0x5FFFFFFF\" , \"type\" : \"INT_RAM\" } }, \"ignoreMemory\" : [ \"Device\" ] } patterns_MCU.json \u00b6 This config file serves the purpose to find all the mapfiles that belong to the firmware on the MCU. We know that there is only two mapfiles we need to find: MCU_Bootloader.map , MCU_Application.map . We will create two keys in the mapfiles object and assign a regex pattern to each. If the mapfile names would not be this simple (for example they would change with every build), we could assign more than one pattern to the keys, but in this case a single pattern is enough. Since these mapfiles follow the default Emma mapfile format, is not needed to add regex patterns to process the content of the mapfiles, the built-in patterns will be used. Otherwise it could be done by adding patterns to the UniquePatternSections and UniquePatternObjects keys (for details see the Emma documentation). To the MCU_Bootloader we have added the ignoration of the SRAM memory area. The reason for this is that the Application and the Bootloader will never run at the same time. During the Application runtime, the data of the Bootloader is not present in the memory, only the code, so the SRAM memory are needs to be ignored to get the correct results. 1 2 3 4 5 6 7 8 9 10 11 { \"mapfiles\" : { \"MCU_Application\" : { \"regex\" : [ \"\\\\bMCU_Application\\\\.map\" ] }, \"MCU_Bootloader\" : { \"regex\" : [ \"\\\\bMCU_Bootloader\\\\.map\" ] \"memRegionExcludes\" : [ \"SRAM\" ] } } } At this point the absolute minimum configuration for the MCU is done. You can try it out by adding the following line to the SOC object in the globalConfig.json : 1 \"ignoreConfigID\" : true This will lead to, that Emma will completely ignore the SOC configID and will not throw an error or warning messages for the missing config files. Emma can be run with the command in the beginning of this document. The MCU configuration can be extended with defining the categories. This will be explained later in this document together with the SOC. In the following, the config files assigned to the SOC will be explained. addressSpaces_SOC.json \u00b6 Just like the addressSpaces_MCU.json of the MCU, this config file describe the memory areas of the SOC and has the same format. You can collect information on the memory areas from the data sheet of the device. For the SOC used in the system, the following memory areas are available: Boot , SRAM , Peripherals and DDR . The \"BOOT\" area is an internal Flash area, where the ROM Bootloader is located. The \"SRAM\" area is an internal RAM area, where data can be stored, and the secondary program loader (SPL) will be loaded to, but in our system none of the components we want to analyse use this area. The Peripherals area is where the different peripheral devices are mapped to. And finally the DDR area where the operating system and the other software units that we want to analyse is located. During the booting process, the third stage bootloader will be loaded to this area as well, but it will not be present after the booting process anymore so it will not be part of the Emma analyse. Based on all these info we will ignore the Boot , SRAM and Peripherals memory areas by adding them to the ignoreMemory array. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 { \"memory\" : { \"Boot\" : { \"start\" : \"0x00000000\" , \"end\" : \"0x0FFFFFFF\" , \"type\" : \"INT_FLASH\" }, \"SRAM\" : { \"start\" : \"0x10000000\" , \"end\" : \"0x1FFFFFFF\" , \"type\" : \"INT_RAM\" }, \"Peripherals\" : { \"start\" : \"0x40000000\" , \"end\" : \"0x5FFFFFFF\" , \"type\" : \"INT_RAM\" }, \"DDR\" : { \"start\" : \"0xC0000000\" , \"end\" : \"0xFFFFFFFF\" , \"type\" : \"EXT_RAM\" } }, \"ignoreMemory\" : [ \"Boot\" , \"SRAM\" , \"Peripherals\" ] } patterns_SOC.json \u00b6 Just like the patterns_MCU.json of the MCU, this config file serves the purpose to find all the mapfiles that belong to the software units of the SOC. Since the operating system of the SOC is using virtual address spaces, this config file will be somewhat more complex than the one of the MCU. We know that there are in total four mapfiles we need to find: SOC_OperatingSystem.map , SOC_Application.map , SOC_NetLogger.map and SOC_monolith.map . The first three contains the sections and the objects for the respective software units. These can be either phyisical and virtual addresses. It is also possible that a software unit has both virtual and physical sections defined in the same mapfile. Because of this, a further config file, the sections_SOC.json is needed as well (for description, see below). The SOC_monolith.map contains the information where the virtual sections will be mapped to in the physical memory. We will create a key in the mapfiles object for each software unit and assign a regex pattern to them. If the mapfile names would not be this simple (for example they would change with every build), we could assign more than one pattern to the keys, but in this case a single pattern is enough. For the software units with a virtual address space, we will define a key VAS to which we will assign a user defined unique name. The virtual address space will be represented in the results with this name. Since these mapfiles follow the default Emma mapfile format, is not needed to add regex patterns to process the content of the mapfiles, the built-in patterns will be used. Otherwise it could be done by adding patterns to the UniquePatternSections and UniquePatternObjects keys (for details see the Emma documentation). For the SOC_monolith.map , we need to create the monoliths object. This object will contain a user defined name for the monolith, in this case SOC_monolith with a regex pattern just like the for the other mapfiles. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"mapfiles\" : { \"SOC_OperatingSystem\" : { \"regex\" : [ \"\\\\bSOC_OperatingSystem\\\\.map\" ] }, \"SOC_Application\" : { \"regex\" : [ \"\\\\bSOC_Application\\\\.map\" ], \"VAS\" : \"APP\" }, \"SOC_NetLogger\" : { \"regex\" : [ \"\\\\bSOC_NetLogger\\\\.map\" ], \"VAS\" : \"NETLOG\" } }, \"monoliths\" : { \"SOC_monolith\" : { \"regex\" : [ \"\\\\bSOC_monolith\\\\.map\" ] } } } virtualSections_SOC.json \u00b6 This config file assigns the sections that were defined in mapfiles to a virtual address space that was defined in the patterns_SOC.json with the VAS key. This is needed because the mapfiles can contain physical and virtual sections as well and Emma needs to identify the virtual ones and assign them to a specific virtual address space. In this configuration only the SOC has virtual address spaces. The MCU does not need a config file like this. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"APP\" : [ \".app_text\" , \".app_rodata\" , \".app_data\" , \".app_bss\" , \".app_heap\" , \".app_stack\" ], \"NETLOG\" : [ \".netlog_text\" , \".netlog_rodata\" , \".netlog_data\" , \".netlog_bss\" , \".netlog_heap\" , \".netlog_stack\" ] } Categorization \u00b6 In the following, the section and object categorization will be explained. Categorization is used to group the sections and objects together in the results. This is useful because then we will be able to filter the results by these groups or calculate the used memory by these groups. The grouping is completely optional, if it is not needed, none of the config files described in this chapter needs to be created. It is also possible to add only some of these config files to the configuration if you do not wish to use all of them. The group names are defined by the user. All the sections and objects for that no group was found, will be assigned to a default group (for details see the Emma documentation). This is useful because you can filter for this default group in the results during the creation of the these config files. Grouping can be done by specifying either the full names of the sections and objects in the categoriesSections.json and categoriesObjects.json respectively or by specifying name patterns for the section and object names in the categoriesSectionsKeywords.json or categoriesObjectsKeywords.json respecively. The name patterns are case-sensitive partial names of the sections and objects. For example the name pattern stack will match for .stack , .process_stack and .user_stack_memory , but not for .Stack or .user_sTaCk . The sections and objects will be first categorized by their full name, and if there was no group found for them, they will be categorized with the name patterns. If after that they still do not have a group, they will be assigned to the default group. categoriesSections.json \u00b6 This config file is used for grouping sections with their full name. 1 2 3 4 5 6 { \"ReservedArea\" : [ \"bootloader\" , \"application\" ] } categoriesSectionsKeywords.json \u00b6 This config file is used for grouping sections with name patterns. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"InterruptVectors\" : [ \"vectors\" ], \"Code\" : [ \"text\" , \"os\" ], \"ConstantData\" : [ \"rodata\" ], \"StaticData\" : [ \"data\" , \"bss\" ], \"DynamicData\" : [ \"stack\" , \"heap\" ] } categoriesObjects.json \u00b6 This config file is used for grouping objects with their full name. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \"Identifiers\" : [ \"identifiers.o\" ], \"Globals\" : [ \"globals.o\" ], \"MCU_RTOS\" : [ \"os_scheduler.o\" , \"os_tick.o\" , \"os_heap.o\" , \"os_queue.o\" , \"os_diagnostics.o\" ], \"MCU_CAN_Stack\" : [ \"can_driver.o\" , \"can_prot_frame.o\" , \"can_prot_transfer.o\" , \"can_prot_message.o\" , \"can_prot_connection.o\" , \"can_prot_control.o\" , \"can_prot_firmware.o\" ], \"SOC_OperatingSystem\" : [ \"kernel.o\" , \"kernel_api.o\" , \"scheduler.o\" , \"memory_manager.o\" , \"network_manager.o\" , \"process_manager.o\" , \"ethernet_driver.o\" , \"tcp_ip_stack.o\" , \"display_driver.o\" , \"touch_driver.o\" ], \"SOC_ApplicationLogging\" : [ \"netlog_lib.o\" , \"logging.o\" ], \"SOC_ApplicationGraphics\" : [ \"gfx_lib.o\" , \"touch_screen.o\" , \"gui_main.o\" , \"gui_animations.o\" ], \"SOC_NetLog\" : [ \"netlog_driver.o\" , \"netlog_filter.o\" , \"netlog_network_handler.o\" , \"netlog_transfer.o\" , \"netlog_connection.o\" ] } categoriesObjectsKeywords.json \u00b6 This config file is used for grouping sections with name patterns. This configuration does not use this file, so it is not present. If your system needs it, you can easily create it based on the Emma documentation. budgets.json \u00b6 This config file defines the available memory resources for every memory type for every configID. It also defines a threshold value so that you can see if the used memory is above your defined reserve limit. This is only needed for the Emma Visualiser, if you only intend to use Emma, you don\u00b4t have to include it to your configurations. For this system, we have defined a 20% reserve that we should not exceed. The values for the \"Budgets\" array are decimal values, and representing Bytes. You can find these values for your device in their documentation. In this case, even though the MCU have the addresses as defined in the addressSpaces_MCU.json, the actually implemented memory is smaller than those. This config file shall contain the memory sizes that physically exist in the device. We have to include every memory type: INT_RAM , EXT_RAM , INT_FLASH , EXT_FLASH . If your project has more than one memory area that are not ignored, with the same type, simply add their sizes together and include them like that in this file. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"Project Threshold in %\" : 80 , \"Budgets\" : [ [ \"MCU\" , \"INT_RAM\" , 262144 ], [ \"MCU\" , \"EXT_RAM\" , 0 ], [ \"MCU\" , \"INT_FLASH\" , 524288 ], [ \"MCU\" , \"EXT_FLASH\" , 0 ], [ \"SOC\" , \"INT_RAM\" , 0 ], [ \"SOC\" , \"EXT_RAM\" , 33554432 ], [ \"SOC\" , \"INT_FLASH\" , 0 ], [ \"SOC\" , \"EXT_FLASH\" , 0 ] ] }","title":"Test Project"},{"location":"test_project/readme.html#test-project","text":"This is an imaginary system, the mapfiles were created by hand and they are following the default Emma mapfile format. The goal of the project is to present a simple system without any complicated parts in order to introduce the new users step-by-step to creating an Emma configuration. The project can be analyzed by running the following commands from the Emma top-level folder: Emma: 1 python Emma.py a --project doc/test_project --mapfiles doc/test_project/mapfiles Emma Visualier: 1 python Emma.py v --project doc/test_project --dir doc/test_project/results --overview --quiet The folder structure of the Test Project: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 +--[test_project] | +-- [mapfiles] # The mapfiles of the project are stored here | +-- [readme] # The folder of this description | +-- [results] # The results of the analyse will be stored here by the commands above | +-- [supplement] # Supplements to the result overview (see Emma Visualiser documentation) | +-- globalConfig.json | +-- addressSpaces_MCU.json | +-- addressSpaces_SOC.json | +-- patterns_MCU.json | +-- patterns_SOC.json | +-- virtualSections_SOC.json | +-- categoriesObjects.json | +-- categoriesSections.json | +-- categoriesObjectsKeywords.json | +-- categoriesSectionsKeywords.json","title":"Test Project"},{"location":"test_project/readme.html#project-description","text":"The project illustrates a system with a hardware that consists of two devices: an MCU and an SOC.","title":"Project description"},{"location":"test_project/readme.html#mcu","text":"The MCU software consists of two firmware, the application and the bootloader. Both of them are loaded into the internal Flash, but they are never running at the same time. They share the same stack area and none of them have a heap. Besides the internal Flash and RAM available on the MCU, there is an external Flash available trough SPI for the software to use. After a system start-up, the execution will be given to the Bootloader. The function of the bootloader is to check version number and the CRC value of the application firmware and in case an update is needed, (newer firmware available or CRC error of the current one) try to update it. The firmware for the update is stored in the external flash. The bootloader is a bare-metal firmware, it does not use an operating system. The function of the application is to load the parameter set from the external Flash memory and run a complex CAN stack. It implements a connection based protocol called CAN_PROT . The protocol makes the Application firmware able to receive a firmware update which will then be stored in the external Flash. After executing the reset command received trough the CAN stack, the Bootloader can flash the application if all the firmware checks pass. The application has a simple RTOS running on it called OS. The memory layout of the MCU:","title":"MCU"},{"location":"test_project/readme.html#soc","text":"The SOC is running a complex operating system that utilizes the memory management unit (MMU) of the processor. The software running on the SOC contains multiple virtual address spaces. Besides the operating system, there are two processes running on the chip: the NetLogger and the application. The NetLogger is a logging framework, trough which the software can be remotely monitored. The log messages are sent from other processes trough the IPC service provided by the operating system. These messages can be accessed and filtered by a remote client trough a TCP/IP connection. The application is handling a capacitive touchscreen trough the Gfx graphics library and other software components. It is presenting animations to the user, which he can control trough the touch screen. The application is creating log messages about every event that occurs trough the NetLog library. The NetLog library will transfer the log messages to the NetLogger framework if available on the system. The memory layout of the SOC:","title":"SOC"},{"location":"test_project/readme.html#creating-the-configuration","text":"This chapter will explain creating the configuration for the project by explaining every step the user should take.","title":"Creating the configuration"},{"location":"test_project/readme.html#globalconfigjson","text":"Creating the project configuration starts with creating the globalConfig.json . This file lists the programmable devices of the system and assigns the further configuration files to configuration. We will add our two devices (MCU and SOC) as JSON objects. For every device, the used compiler and at least two config files must be assigned: the addressSpaces and the patterns. For devices using virtual address spaces, a third one, the sections is needed as well. As we are using Green Hills Compiler, so the mapfiles will be in this format, we will define the value GHS for both of the devices. Since in our system, we have different devices with different memory layout, we have assigned two different addressSpaces config files to them. If your system contains multiple devices of the same type, you can use the same addressSpaces config file for these devices. The patterns config file files are usually unique for all the configIDs. Since the MCU does not have an MMU so it does not have virtual address spaces, we will not assign a sections config file to it. In contrast to the MCU, the SOC does use virtual address spaces, so we will assign a sections config file to it. 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"MCU\" : { \"compiler\" : \"GHS\" , \"addressSpacesPath\" : \"addressSpaces_MCU.json\" , \"patternsPath\" : \"patterns_MCU.json\" }, \"SOC\" : { \"compiler\" : \"GHS\" , \"addressSpacesPath\" : \"addressSpaces_SOC.json\" , \"patternsPath\" : \"patterns_SOC.json\" , \"virtualSectionsPath\" : \"virtualSections_SOC.json\" } } In the following, the config files assigned to the MCU will be explained.","title":"globalConfig.json"},{"location":"test_project/readme.html#addressspaces_mcujson","text":"In this config file, the memory areas of the MCU will be defined. You can collect information on them from the data sheet of the device. For every memory area, we have to define the start and end addresses in bytes and assign a type to it as well. For the possible values of the \"type\", see the Emma documentation. For the MCU used in the system, the following memory areas are available: Code , SRAM and Device . The Code area is an internal Flash area, where the program and the constants will be stored. The SRAM area is an internal RAM area, where data is stored. The last area is the Device , where the SFRs of the controller are located. Since our software will have neither data nor code in this area, we will add it to the ignoreMemory array so it will not be a analysed by Emma. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 { \"memory\" : { \"Code\" : { \"start\" : \"0x00000000\" , \"end\" : \"0x1FFFFFFF\" , \"type\" : \"INT_FLASH\" }, \"SRAM\" : { \"start\" : \"0x20000000\" , \"end\" : \"0x3FFFFFFF\" , \"type\" : \"INT_RAM\" }, \"Device\" : { \"start\" : \"0x40000000\" , \"end\" : \"0x5FFFFFFF\" , \"type\" : \"INT_RAM\" } }, \"ignoreMemory\" : [ \"Device\" ] }","title":"addressSpaces_MCU.json"},{"location":"test_project/readme.html#patterns_mcujson","text":"This config file serves the purpose to find all the mapfiles that belong to the firmware on the MCU. We know that there is only two mapfiles we need to find: MCU_Bootloader.map , MCU_Application.map . We will create two keys in the mapfiles object and assign a regex pattern to each. If the mapfile names would not be this simple (for example they would change with every build), we could assign more than one pattern to the keys, but in this case a single pattern is enough. Since these mapfiles follow the default Emma mapfile format, is not needed to add regex patterns to process the content of the mapfiles, the built-in patterns will be used. Otherwise it could be done by adding patterns to the UniquePatternSections and UniquePatternObjects keys (for details see the Emma documentation). To the MCU_Bootloader we have added the ignoration of the SRAM memory area. The reason for this is that the Application and the Bootloader will never run at the same time. During the Application runtime, the data of the Bootloader is not present in the memory, only the code, so the SRAM memory are needs to be ignored to get the correct results. 1 2 3 4 5 6 7 8 9 10 11 { \"mapfiles\" : { \"MCU_Application\" : { \"regex\" : [ \"\\\\bMCU_Application\\\\.map\" ] }, \"MCU_Bootloader\" : { \"regex\" : [ \"\\\\bMCU_Bootloader\\\\.map\" ] \"memRegionExcludes\" : [ \"SRAM\" ] } } } At this point the absolute minimum configuration for the MCU is done. You can try it out by adding the following line to the SOC object in the globalConfig.json : 1 \"ignoreConfigID\" : true This will lead to, that Emma will completely ignore the SOC configID and will not throw an error or warning messages for the missing config files. Emma can be run with the command in the beginning of this document. The MCU configuration can be extended with defining the categories. This will be explained later in this document together with the SOC. In the following, the config files assigned to the SOC will be explained.","title":"patterns_MCU.json"},{"location":"test_project/readme.html#addressspaces_socjson","text":"Just like the addressSpaces_MCU.json of the MCU, this config file describe the memory areas of the SOC and has the same format. You can collect information on the memory areas from the data sheet of the device. For the SOC used in the system, the following memory areas are available: Boot , SRAM , Peripherals and DDR . The \"BOOT\" area is an internal Flash area, where the ROM Bootloader is located. The \"SRAM\" area is an internal RAM area, where data can be stored, and the secondary program loader (SPL) will be loaded to, but in our system none of the components we want to analyse use this area. The Peripherals area is where the different peripheral devices are mapped to. And finally the DDR area where the operating system and the other software units that we want to analyse is located. During the booting process, the third stage bootloader will be loaded to this area as well, but it will not be present after the booting process anymore so it will not be part of the Emma analyse. Based on all these info we will ignore the Boot , SRAM and Peripherals memory areas by adding them to the ignoreMemory array. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 { \"memory\" : { \"Boot\" : { \"start\" : \"0x00000000\" , \"end\" : \"0x0FFFFFFF\" , \"type\" : \"INT_FLASH\" }, \"SRAM\" : { \"start\" : \"0x10000000\" , \"end\" : \"0x1FFFFFFF\" , \"type\" : \"INT_RAM\" }, \"Peripherals\" : { \"start\" : \"0x40000000\" , \"end\" : \"0x5FFFFFFF\" , \"type\" : \"INT_RAM\" }, \"DDR\" : { \"start\" : \"0xC0000000\" , \"end\" : \"0xFFFFFFFF\" , \"type\" : \"EXT_RAM\" } }, \"ignoreMemory\" : [ \"Boot\" , \"SRAM\" , \"Peripherals\" ] }","title":"addressSpaces_SOC.json"},{"location":"test_project/readme.html#patterns_socjson","text":"Just like the patterns_MCU.json of the MCU, this config file serves the purpose to find all the mapfiles that belong to the software units of the SOC. Since the operating system of the SOC is using virtual address spaces, this config file will be somewhat more complex than the one of the MCU. We know that there are in total four mapfiles we need to find: SOC_OperatingSystem.map , SOC_Application.map , SOC_NetLogger.map and SOC_monolith.map . The first three contains the sections and the objects for the respective software units. These can be either phyisical and virtual addresses. It is also possible that a software unit has both virtual and physical sections defined in the same mapfile. Because of this, a further config file, the sections_SOC.json is needed as well (for description, see below). The SOC_monolith.map contains the information where the virtual sections will be mapped to in the physical memory. We will create a key in the mapfiles object for each software unit and assign a regex pattern to them. If the mapfile names would not be this simple (for example they would change with every build), we could assign more than one pattern to the keys, but in this case a single pattern is enough. For the software units with a virtual address space, we will define a key VAS to which we will assign a user defined unique name. The virtual address space will be represented in the results with this name. Since these mapfiles follow the default Emma mapfile format, is not needed to add regex patterns to process the content of the mapfiles, the built-in patterns will be used. Otherwise it could be done by adding patterns to the UniquePatternSections and UniquePatternObjects keys (for details see the Emma documentation). For the SOC_monolith.map , we need to create the monoliths object. This object will contain a user defined name for the monolith, in this case SOC_monolith with a regex pattern just like the for the other mapfiles. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"mapfiles\" : { \"SOC_OperatingSystem\" : { \"regex\" : [ \"\\\\bSOC_OperatingSystem\\\\.map\" ] }, \"SOC_Application\" : { \"regex\" : [ \"\\\\bSOC_Application\\\\.map\" ], \"VAS\" : \"APP\" }, \"SOC_NetLogger\" : { \"regex\" : [ \"\\\\bSOC_NetLogger\\\\.map\" ], \"VAS\" : \"NETLOG\" } }, \"monoliths\" : { \"SOC_monolith\" : { \"regex\" : [ \"\\\\bSOC_monolith\\\\.map\" ] } } }","title":"patterns_SOC.json"},{"location":"test_project/readme.html#virtualsections_socjson","text":"This config file assigns the sections that were defined in mapfiles to a virtual address space that was defined in the patterns_SOC.json with the VAS key. This is needed because the mapfiles can contain physical and virtual sections as well and Emma needs to identify the virtual ones and assign them to a specific virtual address space. In this configuration only the SOC has virtual address spaces. The MCU does not need a config file like this. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \"APP\" : [ \".app_text\" , \".app_rodata\" , \".app_data\" , \".app_bss\" , \".app_heap\" , \".app_stack\" ], \"NETLOG\" : [ \".netlog_text\" , \".netlog_rodata\" , \".netlog_data\" , \".netlog_bss\" , \".netlog_heap\" , \".netlog_stack\" ] }","title":"virtualSections_SOC.json"},{"location":"test_project/readme.html#categorization","text":"In the following, the section and object categorization will be explained. Categorization is used to group the sections and objects together in the results. This is useful because then we will be able to filter the results by these groups or calculate the used memory by these groups. The grouping is completely optional, if it is not needed, none of the config files described in this chapter needs to be created. It is also possible to add only some of these config files to the configuration if you do not wish to use all of them. The group names are defined by the user. All the sections and objects for that no group was found, will be assigned to a default group (for details see the Emma documentation). This is useful because you can filter for this default group in the results during the creation of the these config files. Grouping can be done by specifying either the full names of the sections and objects in the categoriesSections.json and categoriesObjects.json respectively or by specifying name patterns for the section and object names in the categoriesSectionsKeywords.json or categoriesObjectsKeywords.json respecively. The name patterns are case-sensitive partial names of the sections and objects. For example the name pattern stack will match for .stack , .process_stack and .user_stack_memory , but not for .Stack or .user_sTaCk . The sections and objects will be first categorized by their full name, and if there was no group found for them, they will be categorized with the name patterns. If after that they still do not have a group, they will be assigned to the default group.","title":"Categorization"},{"location":"test_project/readme.html#categoriessectionsjson","text":"This config file is used for grouping sections with their full name. 1 2 3 4 5 6 { \"ReservedArea\" : [ \"bootloader\" , \"application\" ] }","title":"categoriesSections.json"},{"location":"test_project/readme.html#categoriessectionskeywordsjson","text":"This config file is used for grouping sections with name patterns. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"InterruptVectors\" : [ \"vectors\" ], \"Code\" : [ \"text\" , \"os\" ], \"ConstantData\" : [ \"rodata\" ], \"StaticData\" : [ \"data\" , \"bss\" ], \"DynamicData\" : [ \"stack\" , \"heap\" ] }","title":"categoriesSectionsKeywords.json"},{"location":"test_project/readme.html#categoriesobjectsjson","text":"This config file is used for grouping objects with their full name. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 { \"Identifiers\" : [ \"identifiers.o\" ], \"Globals\" : [ \"globals.o\" ], \"MCU_RTOS\" : [ \"os_scheduler.o\" , \"os_tick.o\" , \"os_heap.o\" , \"os_queue.o\" , \"os_diagnostics.o\" ], \"MCU_CAN_Stack\" : [ \"can_driver.o\" , \"can_prot_frame.o\" , \"can_prot_transfer.o\" , \"can_prot_message.o\" , \"can_prot_connection.o\" , \"can_prot_control.o\" , \"can_prot_firmware.o\" ], \"SOC_OperatingSystem\" : [ \"kernel.o\" , \"kernel_api.o\" , \"scheduler.o\" , \"memory_manager.o\" , \"network_manager.o\" , \"process_manager.o\" , \"ethernet_driver.o\" , \"tcp_ip_stack.o\" , \"display_driver.o\" , \"touch_driver.o\" ], \"SOC_ApplicationLogging\" : [ \"netlog_lib.o\" , \"logging.o\" ], \"SOC_ApplicationGraphics\" : [ \"gfx_lib.o\" , \"touch_screen.o\" , \"gui_main.o\" , \"gui_animations.o\" ], \"SOC_NetLog\" : [ \"netlog_driver.o\" , \"netlog_filter.o\" , \"netlog_network_handler.o\" , \"netlog_transfer.o\" , \"netlog_connection.o\" ] }","title":"categoriesObjects.json"},{"location":"test_project/readme.html#categoriesobjectskeywordsjson","text":"This config file is used for grouping sections with name patterns. This configuration does not use this file, so it is not present. If your system needs it, you can easily create it based on the Emma documentation.","title":"categoriesObjectsKeywords.json"},{"location":"test_project/readme.html#budgetsjson","text":"This config file defines the available memory resources for every memory type for every configID. It also defines a threshold value so that you can see if the used memory is above your defined reserve limit. This is only needed for the Emma Visualiser, if you only intend to use Emma, you don\u00b4t have to include it to your configurations. For this system, we have defined a 20% reserve that we should not exceed. The values for the \"Budgets\" array are decimal values, and representing Bytes. You can find these values for your device in their documentation. In this case, even though the MCU have the addresses as defined in the addressSpaces_MCU.json, the actually implemented memory is smaller than those. This config file shall contain the memory sizes that physically exist in the device. We have to include every memory type: INT_RAM , EXT_RAM , INT_FLASH , EXT_FLASH . If your project has more than one memory area that are not ignored, with the same type, simply add their sizes together and include them like that in this file. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \"Project Threshold in %\" : 80 , \"Budgets\" : [ [ \"MCU\" , \"INT_RAM\" , 262144 ], [ \"MCU\" , \"EXT_RAM\" , 0 ], [ \"MCU\" , \"INT_FLASH\" , 524288 ], [ \"MCU\" , \"EXT_FLASH\" , 0 ], [ \"SOC\" , \"INT_RAM\" , 0 ], [ \"SOC\" , \"EXT_RAM\" , 33554432 ], [ \"SOC\" , \"INT_FLASH\" , 0 ], [ \"SOC\" , \"EXT_FLASH\" , 0 ] ] }","title":"budgets.json"},{"location":"test_project/supplement/terms_and_notations.html","text":"","title":"Terms and notations"}]}